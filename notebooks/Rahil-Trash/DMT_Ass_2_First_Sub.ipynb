{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lot of work still remains, this was the first submission module which creates a csv file we upload to kaggle for submission.\n",
        "\n",
        "-> LightGBM LambdaRank + advanced features (percentile rank, delta, CTR, bucketization). Trained on 400k rows, tested on full test set.\n",
        "\n",
        "-> Enriched model with 28 features (log price, group deltas, CTR, star bucket). Model: LightGBM LambdaRank (early stopping, ndcg@5 avg ≈ 0.407). Chunked test inference.\n",
        "\n",
        "-> Full test re-ranking using LightGBM LambdaRank with engineered 28-feature pipeline. Expecting ndcg@5 > 0.40.\n"
      ],
      "metadata": {
        "id": "x_tS2niOyFYQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu0ANGoDBZIs",
        "outputId": "a331ecee-5f92-4e6c-f7fe-8d0b1cc031d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1znhL6ZFc_m5ozMfDvBj9b80de4a6OSyQ\n",
            "From (redirected): https://drive.google.com/uc?id=1znhL6ZFc_m5ozMfDvBj9b80de4a6OSyQ&confirm=t&uuid=487836a0-5387-4e59-9b7e-4f9a74ee43f8\n",
            "To: /content/dmt_dataset.zip\n",
            "100% 285M/285M [00:05<00:00, 48.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 📦 Setup: Mount Google Drive & Install Dependencies\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q kaggle pandas numpy matplotlib seaborn\n",
        "\n",
        "# 📥 Download from Google Drive via gdown\n",
        "!gdown --id 1znhL6ZFc_m5ozMfDvBj9b80de4a6OSyQ --output dmt_dataset.zip\n",
        "\n",
        "# 📂 Extract the zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"dmt_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"🔍 Contents of /data after unzipping:\")\n",
        "for root, dirs, files in os.walk(\"data\"):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyjABqqXCMuE",
        "outputId": "c6e3a147-14c2-4392-ccd7-9a257ee01ed2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Contents of /data after unzipping:\n",
            "data/training_set_VU_DM.csv\n",
            "data/submission_sample.csv\n",
            "data/test_set_VU_DM.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Create `data/` folder\n",
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# ✅ Step 2: Extract the zip\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"dmt_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "# ✅ Step 3: Load CSVs\n",
        "import pandas as pd\n",
        "\n",
        "train_path = \"data/training_set_VU_DM.csv\"\n",
        "test_path = \"data/test_set_VU_DM.csv\"\n",
        "\n",
        "\n",
        "if os.path.exists(train_path) and os.path.exists(test_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "\n",
        "    print(\"✅ Successfully loaded the datasets!\")\n",
        "    print(\"Train shape:\", train.shape)\n",
        "    print(\"Test shape :\", test.shape)\n",
        "    display(train.head())\n",
        "else:\n",
        "    print(\"❌ train.csv or test.csv not found in /data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "axlRUc37CN2R",
        "outputId": "d1494d9e-2429-4491-d443-8d5d7b7bb2af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully loaded the datasets!\n",
            "Train shape: (4958347, 54)\n",
            "Test shape : (4959183, 50)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
              "0        1  2013-04-04 08:32:15       12                          187   \n",
              "1        1  2013-04-04 08:32:15       12                          187   \n",
              "2        1  2013-04-04 08:32:15       12                          187   \n",
              "3        1  2013-04-04 08:32:15       12                          187   \n",
              "4        1  2013-04-04 08:32:15       12                          187   \n",
              "\n",
              "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
              "0                      NaN                   NaN              219      893   \n",
              "1                      NaN                   NaN              219    10404   \n",
              "2                      NaN                   NaN              219    21315   \n",
              "3                      NaN                   NaN              219    27348   \n",
              "4                      NaN                   NaN              219    29604   \n",
              "\n",
              "   prop_starrating  prop_review_score  ...  comp6_rate_percent_diff  \\\n",
              "0                3                3.5  ...                      NaN   \n",
              "1                4                4.0  ...                      NaN   \n",
              "2                3                4.5  ...                      NaN   \n",
              "3                2                4.0  ...                      NaN   \n",
              "4                4                3.5  ...                      NaN   \n",
              "\n",
              "   comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
              "0         NaN        NaN                      NaN         0.0        0.0   \n",
              "1         NaN        NaN                      NaN         0.0        0.0   \n",
              "2         NaN        NaN                      NaN         0.0        0.0   \n",
              "3         NaN        NaN                      NaN        -1.0        0.0   \n",
              "4         NaN        NaN                      NaN         0.0        0.0   \n",
              "\n",
              "   comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
              "0                      NaN           0                 NaN             0  \n",
              "1                      NaN           0                 NaN             0  \n",
              "2                      NaN           0                 NaN             0  \n",
              "3                      5.0           0                 NaN             0  \n",
              "4                      NaN           0                 NaN             0  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afc241e1-b9f2-49cf-96a2-b2a15eec0e81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>srch_id</th>\n",
              "      <th>date_time</th>\n",
              "      <th>site_id</th>\n",
              "      <th>visitor_location_country_id</th>\n",
              "      <th>visitor_hist_starrating</th>\n",
              "      <th>visitor_hist_adr_usd</th>\n",
              "      <th>prop_country_id</th>\n",
              "      <th>prop_id</th>\n",
              "      <th>prop_starrating</th>\n",
              "      <th>prop_review_score</th>\n",
              "      <th>...</th>\n",
              "      <th>comp6_rate_percent_diff</th>\n",
              "      <th>comp7_rate</th>\n",
              "      <th>comp7_inv</th>\n",
              "      <th>comp7_rate_percent_diff</th>\n",
              "      <th>comp8_rate</th>\n",
              "      <th>comp8_inv</th>\n",
              "      <th>comp8_rate_percent_diff</th>\n",
              "      <th>click_bool</th>\n",
              "      <th>gross_bookings_usd</th>\n",
              "      <th>booking_bool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-04-04 08:32:15</td>\n",
              "      <td>12</td>\n",
              "      <td>187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219</td>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-04-04 08:32:15</td>\n",
              "      <td>12</td>\n",
              "      <td>187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219</td>\n",
              "      <td>10404</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-04-04 08:32:15</td>\n",
              "      <td>12</td>\n",
              "      <td>187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219</td>\n",
              "      <td>21315</td>\n",
              "      <td>3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-04-04 08:32:15</td>\n",
              "      <td>12</td>\n",
              "      <td>187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219</td>\n",
              "      <td>27348</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-04-04 08:32:15</td>\n",
              "      <td>12</td>\n",
              "      <td>187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219</td>\n",
              "      <td>29604</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afc241e1-b9f2-49cf-96a2-b2a15eec0e81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afc241e1-b9f2-49cf-96a2-b2a15eec0e81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afc241e1-b9f2-49cf-96a2-b2a15eec0e81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a8a685c6-f85e-47ab-9234-b98787ff4b54\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8a685c6-f85e-47ab-9234-b98787ff4b54')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a8a685c6-f85e-47ab-9234-b98787ff4b54 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn lightgbm xgboost catboost tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hqLNHPHCqtv",
        "outputId": "881b3691-4619-4067-f112-81d82d071264"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✅ Dataset shape:\", train.shape)\n",
        "print(\"🧩 Unique searches:\", train['srch_id'].nunique())\n",
        "print(\"🏨 Unique properties:\", train['prop_id'].nunique())\n",
        "print(\"📌 Columns with most nulls:\\n\")\n",
        "print(train.isnull().sum().sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "id": "gDpaORIKGtEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb98eb7e-c990-41c2-d8ce-6cd8dd2e57df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset shape: (4958347, 54)\n",
            "🧩 Unique searches: 199795\n",
            "🏨 Unique properties: 129113\n",
            "📌 Columns with most nulls:\n",
            "\n",
            "comp1_rate_percent_diff    4863908\n",
            "comp6_rate_percent_diff    4862173\n",
            "comp1_rate                 4838417\n",
            "comp1_inv                  4828788\n",
            "comp4_rate_percent_diff    4827261\n",
            "gross_bookings_usd         4819957\n",
            "comp7_rate_percent_diff    4819832\n",
            "comp6_rate                 4718190\n",
            "visitor_hist_starrating    4706481\n",
            "visitor_hist_adr_usd       4705359\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # === Load Data ===\n",
        "# train = pd.read_csv(\"/content/data/training_set_VU_DM.csv\")  # replace with actual path\n",
        "# sample_frac = 0.05  # Adjust based on available memory\n",
        "# train = train.sample(frac=sample_frac, random_state=42)\n",
        "\n",
        "# # === Missing Value Handling ===\n",
        "# missing_features = [\n",
        "#     'visitor_hist_adr_usd', 'visitor_hist_starrating', 'prop_review_score',\n",
        "#     'comp1_rate_percent_diff', 'orig_destination_distance'\n",
        "# ]\n",
        "\n",
        "# for col in missing_features:\n",
        "#     train[f'is_null_{col}'] = train[col].isnull().astype(int)\n",
        "\n",
        "# train['visitor_hist_adr_usd'].fillna(-1, inplace=True)\n",
        "# train['visitor_hist_starrating'].fillna(-1, inplace=True)\n",
        "# train['prop_review_score'].fillna(train['prop_review_score'].median(), inplace=True)\n",
        "# train['orig_destination_distance'].fillna(train['orig_destination_distance'].median(), inplace=True)\n",
        "# train['comp1_rate_percent_diff'].fillna(-999, inplace=True)\n",
        "\n",
        "# # === Log Transform Skewed Features ===\n",
        "# train['price_usd_log'] = np.log1p(train['price_usd'])\n",
        "# train['distance_log'] = np.log1p(train['orig_destination_distance'])\n",
        "\n",
        "# # === Outlier Clipping ===\n",
        "# price_upper = train['price_usd'].quantile(0.995)\n",
        "# train = train[train['price_usd'] < price_upper]\n",
        "\n",
        "# # === Group-wise Percentile Ranks ===\n",
        "# train['price_rank_pct'] = train.groupby('srch_id')['price_usd'].rank(pct=True)\n",
        "# train['location_score_rank_pct'] = train.groupby('srch_id')['prop_location_score1'].rank(pct=True)\n",
        "# train['review_score_rank_pct'] = train.groupby('srch_id')['prop_review_score'].rank(pct=True)\n",
        "\n",
        "# # === Feature Engineering ===\n",
        "# train['price_vs_hist'] = train['price_usd'] - train['visitor_hist_adr_usd']\n",
        "# train['star_diff'] = train['prop_starrating'] - train['visitor_hist_starrating']\n",
        "# train['promo_available_in_group'] = train.groupby('srch_id')['promotion_flag'].transform('sum')\n",
        "\n",
        "# # === Label Engineering ===\n",
        "# train['target'] = 5 * train['booking_bool'] + train['click_bool']\n",
        "\n",
        "# # === Save EDA Output ===\n",
        "# eda_cols = [\n",
        "#     'price_usd', 'price_usd_log', 'price_rank_pct', 'location_score_rank_pct',\n",
        "#     'review_score_rank_pct', 'price_vs_hist', 'star_diff', 'promo_available_in_group',\n",
        "#     'target'\n",
        "# ]\n",
        "# # train[eda_cols].to_csv(\"eda_sample_output.csv\", index=False)\n",
        "# # print(\"EDA output saved to eda_sample_output.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "VfdTc2iWQQ-j",
        "outputId": "79a59766-2632-4c6a-f9ed-3539aae70b62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-823fbcbc7d7a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# === Load Data ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data/training_set_VU_DM.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# replace with actual path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msample_frac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m  \u001b[0;31m# Adjust based on available memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === LOAD SMALL SAMPLE FOR SAFE EDA ===\n",
        "chunksize = 100_000  # Load in chunks to reduce memory\n",
        "sample_frac = 0.01   # Further sampling per chunk\n",
        "\n",
        "chunks = pd.read_csv(\"/content/data/training_set_VU_DM.csv\", chunksize=chunksize)\n",
        "\n",
        "sampled_data = []\n",
        "for chunk in chunks:\n",
        "    sampled_chunk = chunk.sample(frac=sample_frac, random_state=42)\n",
        "    sampled_data.append(sampled_chunk)\n",
        "\n",
        "train = pd.concat(sampled_data, ignore_index=True)\n",
        "\n",
        "# === NULL HANDLING ===\n",
        "for col in ['visitor_hist_adr_usd', 'visitor_hist_starrating', 'prop_review_score',\n",
        "            'comp1_rate_percent_diff', 'orig_destination_distance']:\n",
        "    train[f'is_null_{col}'] = train[col].isnull().astype(int)\n",
        "\n",
        "train['visitor_hist_adr_usd'].fillna(-1, inplace=True)\n",
        "train['visitor_hist_starrating'].fillna(-1, inplace=True)\n",
        "train['prop_review_score'].fillna(train['prop_review_score'].median(), inplace=True)\n",
        "train['orig_destination_distance'].fillna(train['orig_destination_distance'].median(), inplace=True)\n",
        "train['comp1_rate_percent_diff'].fillna(-999, inplace=True)\n",
        "\n",
        "# === SAFE TRANSFORMATIONS ===\n",
        "train['price_usd_log'] = np.log1p(train['price_usd'])\n",
        "train['distance_log'] = np.log1p(train['orig_destination_distance'])\n",
        "\n",
        "# === OUTLIER FILTERING ===\n",
        "price_upper = train['price_usd'].quantile(0.995)\n",
        "train = train[train['price_usd'] < price_upper]\n",
        "\n",
        "# === SAFE RANKING: only on a small subset of srch_id ===\n",
        "top_search_ids = train['srch_id'].value_counts().head(100).index\n",
        "train_subset = train[train['srch_id'].isin(top_search_ids)].copy()\n",
        "\n",
        "for col in ['price_usd', 'prop_location_score1', 'prop_review_score']:\n",
        "    train_subset[f'{col}_rank_pct'] = train_subset.groupby('srch_id')[col].rank(pct=True)\n",
        "\n",
        "# === FEATURE ENGINEERING ===\n",
        "train_subset['price_vs_hist'] = train_subset['price_usd'] - train_subset['visitor_hist_adr_usd']\n",
        "train_subset['star_diff'] = train_subset['prop_starrating'] - train_subset['visitor_hist_starrating']\n",
        "train_subset['promo_available_in_group'] = train_subset.groupby('srch_id')['promotion_flag'].transform('sum')\n",
        "train_subset['target'] = 5 * train_subset['booking_bool'] + train_subset['click_bool']\n",
        "\n",
        "# === EXPORT RESULT ===\n",
        "eda_cols = [col for col in train_subset.columns if 'rank_pct' in col or col in [\n",
        "    'price_usd', 'price_usd_log', 'distance_log', 'price_vs_hist',\n",
        "    'star_diff', 'promo_available_in_group', 'target'\n",
        "]]\n",
        "train_subset[eda_cols].to_csv(\"eda_sample_output_small.csv\", index=False)\n",
        "print(\"Sampled EDA output saved to eda_sample_output_small.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhBx_IubLu-J",
        "outputId": "f19c005d-72fb-4fe4-c71f-663ceae66bf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled EDA output saved to eda_sample_output_small.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-0d4c1a9ce34e>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['visitor_hist_adr_usd'].fillna(-1, inplace=True)\n",
            "<ipython-input-2-0d4c1a9ce34e>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['visitor_hist_starrating'].fillna(-1, inplace=True)\n",
            "<ipython-input-2-0d4c1a9ce34e>:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['prop_review_score'].fillna(train['prop_review_score'].median(), inplace=True)\n",
            "<ipython-input-2-0d4c1a9ce34e>:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['orig_destination_distance'].fillna(train['orig_destination_distance'].median(), inplace=True)\n",
            "<ipython-input-2-0d4c1a9ce34e>:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['comp1_rate_percent_diff'].fillna(-999, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def transform_features(df):\n",
        "    # Null indicators\n",
        "    for col in ['visitor_hist_adr_usd', 'visitor_hist_starrating', 'prop_review_score',\n",
        "                'comp1_rate_percent_diff', 'orig_destination_distance']:\n",
        "        df[f'is_null_{col}'] = df[col].isnull().astype(int)\n",
        "\n",
        "    df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(-1)\n",
        "    df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(-1)\n",
        "    df['prop_review_score'] = df['prop_review_score'].fillna(df['prop_review_score'].median())\n",
        "    df['orig_destination_distance'] = df['orig_destination_distance'].fillna(df['orig_destination_distance'].median())\n",
        "    df['comp1_rate_percent_diff'] = df['comp1_rate_percent_diff'].fillna(-999)\n",
        "\n",
        "    # Log transforms\n",
        "    df['price_usd_log'] = np.log1p(df['price_usd'])\n",
        "    df['distance_log'] = np.log1p(df['orig_destination_distance'])\n",
        "\n",
        "    # Feature engineering\n",
        "    df['price_vs_hist'] = df['price_usd'] - df['visitor_hist_adr_usd']\n",
        "    df['star_diff'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
        "\n",
        "    # Label (click/book)\n",
        "    df['target'] = 5 * df['booking_bool'] + df['click_bool']\n",
        "\n",
        "    return df\n",
        "\n",
        "# === CHUNKED PROCESSING ===\n",
        "input_path = \"/content/data/training_set_VU_DM.csv\"\n",
        "output_path = \"train_transformed.csv\"\n",
        "chunksize = 500_000\n",
        "first_chunk = True\n",
        "\n",
        "reader = pd.read_csv(input_path, chunksize=chunksize)\n",
        "\n",
        "for chunk in reader:\n",
        "    transformed = transform_features(chunk)\n",
        "\n",
        "    # Append to CSV\n",
        "    if first_chunk:\n",
        "        transformed.to_csv(output_path, index=False, mode='w')  # Write header\n",
        "        first_chunk = False\n",
        "    else:\n",
        "        transformed.to_csv(output_path, index=False, header=False, mode='a')  # Append without header\n",
        "\n",
        "print(\"✅ All chunks processed. Transformed file saved as:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bba4YukZMODo",
        "outputId": "c766f7cc-eec9-4fd1-a962-3e1492e69b54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All chunks processed. Transformed file saved as: train_transformed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read just a small preview (first 500 rows)\n",
        "df = pd.read_csv(\"train_transformed.csv\", nrows=500)\n",
        "\n",
        "# 1. Check if key engineered columns exist\n",
        "print(\"✅ Columns present:\\n\", df.columns.tolist())\n",
        "\n",
        "# 2. Check if log transform worked\n",
        "print(\"\\n📊 Log Price Sample:\")\n",
        "print(df[['price_usd', 'price_usd_log']].head())\n",
        "\n",
        "# 3. Check for null indicators\n",
        "print(\"\\n🕵️ Null indicator flags:\")\n",
        "print([col for col in df.columns if col.startswith(\"is_null_\")])\n",
        "\n",
        "# 4. Check if target exists and looks correct\n",
        "print(\"\\n🎯 Target column check:\")\n",
        "print(df['target'].value_counts())\n",
        "\n",
        "# 5. Check feature diffs\n",
        "print(\"\\n💡 Feature diffs preview:\")\n",
        "print(df[['price_vs_hist', 'star_diff']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk0rkudTOQB0",
        "outputId": "24f981bb-7830-4825-c1bb-dd55cddc37e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Columns present:\n",
            " ['srch_id', 'date_time', 'site_id', 'visitor_location_country_id', 'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id', 'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool', 'prop_location_score1', 'prop_location_score2', 'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool', 'srch_query_affinity_score', 'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv', 'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv', 'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv', 'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv', 'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv', 'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv', 'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv', 'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv', 'comp8_rate_percent_diff', 'click_bool', 'gross_bookings_usd', 'booking_bool', 'is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating', 'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff', 'is_null_orig_destination_distance', 'price_usd_log', 'distance_log', 'price_vs_hist', 'star_diff', 'target']\n",
            "\n",
            "📊 Log Price Sample:\n",
            "   price_usd  price_usd_log\n",
            "0     104.77       4.661267\n",
            "1     170.74       5.145982\n",
            "2     179.80       5.197391\n",
            "3     602.77       6.403193\n",
            "4     143.58       4.973833\n",
            "\n",
            "🕵️ Null indicator flags:\n",
            "['is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating', 'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff', 'is_null_orig_destination_distance']\n",
            "\n",
            "🎯 Target column check:\n",
            "target\n",
            "0    479\n",
            "6     12\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "💡 Feature diffs preview:\n",
            "   price_vs_hist  star_diff\n",
            "0         105.77        4.0\n",
            "1         171.74        5.0\n",
            "2         180.80        4.0\n",
            "3         603.77        3.0\n",
            "4         144.58        5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['price_usd_log'].hist(bins=50)\n",
        "plt.title(\"Distribution of log(price_usd)\")\n",
        "plt.xlabel(\"log(price_usd)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "zY6N9M-YP9Yj",
        "outputId": "455c3589-60d7-42fe-c0be-df2bf7bfa5f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm scikit-learn pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXrPz8e5QIet",
        "outputId": "77671232-28cc-44ea-9bb1-491b1aa51381"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# task3_lambdarank.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from lightgbm import LGBMRanker\n",
        "from sklearn.metrics import ndcg_score\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "\n",
        "# === Load Transformed Data ===\n",
        "df = pd.read_csv(\"train_transformed.csv\", nrows=200_000)  # Adjust if needed\n",
        "\n",
        "# === Select Features ===\n",
        "features = [\n",
        "    'price_usd_log', 'distance_log', 'prop_location_score1',\n",
        "    'prop_starrating', 'prop_review_score', 'prop_log_historical_price',\n",
        "    'srch_length_of_stay', 'srch_booking_window',\n",
        "    'srch_adults_count', 'srch_children_count',\n",
        "    'promotion_flag', 'star_diff', 'price_vs_hist',\n",
        "    'is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating',\n",
        "    'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff',\n",
        "    'is_null_orig_destination_distance'\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df['target']\n",
        "groups = df['srch_id']\n",
        "\n",
        "# === Prepare GroupKFold for Group-aware splitting ===\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
        "    print(f\"\\n🧪 Fold {fold+1} training...\")\n",
        "\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "    group_train = X_train.groupby(groups.iloc[train_idx]).size().values\n",
        "    group_val = X_val.groupby(groups.iloc[val_idx]).size().values\n",
        "\n",
        "    # === Initialize LightGBM Ranker ===\n",
        "    model = LGBMRanker(\n",
        "        objective='lambdarank',\n",
        "        metric='ndcg',\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # === Train Model ===\n",
        "    model.fit(\n",
        "    X_train, y_train,\n",
        "    group=group_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[group_val],\n",
        "    eval_at=[5],\n",
        "    callbacks=[\n",
        "        early_stopping(stopping_rounds=10),\n",
        "        log_evaluation(period=10)\n",
        "    ]\n",
        ")\n",
        "\n",
        "    # === Evaluate with NDCG@5 ===\n",
        "    pred = model.predict(X_val)\n",
        "    val_df = df.iloc[val_idx].copy()\n",
        "    val_df['pred'] = pred\n",
        "\n",
        "    ndcg_vals = []\n",
        "    for srch_id, group in val_df.groupby('srch_id'):\n",
        "        if group['target'].sum() == 0:  # avoid all-zero targets\n",
        "            continue\n",
        "        y_true = group[['target']].values.T\n",
        "        y_score = group[['pred']].values.T\n",
        "        ndcg_vals.append(ndcg_score(y_true, y_score, k=5))\n",
        "\n",
        "    mean_ndcg = sum(ndcg_vals) / len(ndcg_vals)\n",
        "    print(f\"✅ Fold {fold+1} NDCG@5: {mean_ndcg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkgkJoGTm4T",
        "outputId": "a1253852-913c-4b6e-8ecf-76b68a74e721"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Fold 1 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1711\n",
            "[LightGBM] [Info] Number of data points in the train set: 159999, number of used features: 18\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.280078\n",
            "[20]\tvalid_0's ndcg@5: 0.274034\n",
            "Early stopping, best iteration is:\n",
            "[10]\tvalid_0's ndcg@5: 0.280078\n",
            "✅ Fold 1 NDCG@5: 0.2811\n",
            "\n",
            "🧪 Fold 2 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1700\n",
            "[LightGBM] [Info] Number of data points in the train set: 159999, number of used features: 18\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.279045\n",
            "Early stopping, best iteration is:\n",
            "[9]\tvalid_0's ndcg@5: 0.283621\n",
            "✅ Fold 2 NDCG@5: 0.2841\n",
            "\n",
            "🧪 Fold 3 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1702\n",
            "[LightGBM] [Info] Number of data points in the train set: 159999, number of used features: 18\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.27411\n",
            "[20]\tvalid_0's ndcg@5: 0.269897\n",
            "Early stopping, best iteration is:\n",
            "[12]\tvalid_0's ndcg@5: 0.275509\n",
            "✅ Fold 3 NDCG@5: 0.2763\n",
            "\n",
            "🧪 Fold 4 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1708\n",
            "[LightGBM] [Info] Number of data points in the train set: 159999, number of used features: 18\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.274822\n",
            "[20]\tvalid_0's ndcg@5: 0.275256\n",
            "Early stopping, best iteration is:\n",
            "[15]\tvalid_0's ndcg@5: 0.277513\n",
            "✅ Fold 4 NDCG@5: 0.2792\n",
            "\n",
            "🧪 Fold 5 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020565 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1711\n",
            "[LightGBM] [Info] Number of data points in the train set: 160004, number of used features: 18\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.271662\n",
            "[20]\tvalid_0's ndcg@5: 0.268397\n",
            "[30]\tvalid_0's ndcg@5: 0.267536\n",
            "Early stopping, best iteration is:\n",
            "[25]\tvalid_0's ndcg@5: 0.273313\n",
            "✅ Fold 5 NDCG@5: 0.2740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def enrich_features(df):\n",
        "    # --- Ranks within each search ---\n",
        "    df['price_rank_pct'] = df.groupby('srch_id')['price_usd'].rank(pct=True)\n",
        "    df['score1_rank_pct'] = df.groupby('srch_id')['prop_location_score1'].rank(pct=True)\n",
        "    df['review_score_rank_pct'] = df.groupby('srch_id')['prop_review_score'].rank(pct=True)\n",
        "\n",
        "    # --- Deltas from srch_id group means ---\n",
        "    df['price_vs_group_mean'] = df['price_usd'] - df.groupby('srch_id')['price_usd'].transform('mean')\n",
        "    df['score1_vs_group_mean'] = df['prop_location_score1'] - df.groupby('srch_id')['prop_location_score1'].transform('mean')\n",
        "    df['review_vs_group_mean'] = df['prop_review_score'] - df.groupby('srch_id')['prop_review_score'].transform('mean')\n",
        "\n",
        "    # --- Price Bucket ---\n",
        "    df['price_bucket'] = pd.cut(df['price_usd_log'], bins=[-np.inf, 4.5, 5.5, np.inf], labels=['low', 'medium', 'high'])\n",
        "\n",
        "    # --- Star Rating Bucket ---\n",
        "    df['star_rating_bucket'] = pd.cut(df['prop_starrating'], bins=[0, 2, 3.5, 5], labels=['economy', 'standard', 'premium'])\n",
        "\n",
        "    # --- Day of Week & One-hot ---\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
        "    day_dummies = pd.get_dummies(df['day_of_week'], prefix='dow')\n",
        "    df = pd.concat([df, day_dummies], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Property-level CTR + Booking Rate (precompute ONCE) ===\n",
        "base = pd.read_csv(\"train_transformed.csv\", usecols=['prop_id', 'click_bool', 'booking_bool'])\n",
        "prop_stats = base.groupby('prop_id').agg({\n",
        "    'click_bool': 'mean',\n",
        "    'booking_bool': 'mean'\n",
        "}).rename(columns={\n",
        "    'click_bool': 'prop_ctr',\n",
        "    'booking_bool': 'prop_booking_rate'\n",
        "}).reset_index()\n",
        "del base\n",
        "\n",
        "# === Chunked Processing and Saving ===\n",
        "chunksize = 500_000\n",
        "reader = pd.read_csv(\"train_transformed.csv\", chunksize=chunksize)\n",
        "first = True\n",
        "\n",
        "for i, chunk in enumerate(reader):\n",
        "    chunk = chunk.merge(prop_stats, on='prop_id', how='left')\n",
        "    chunk = enrich_features(chunk)\n",
        "\n",
        "    out_mode = 'w' if first else 'a'\n",
        "    header = first\n",
        "    chunk.to_csv(\"train_enriched.csv\", mode=out_mode, index=False, header=header)\n",
        "    first = False\n",
        "    print(f\"✅ Chunk {i+1} saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmKODEQ_Tqmt",
        "outputId": "3c901974-2ac2-4fa3-b1c2-a0f30e52e514"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chunk 1 saved.\n",
            "✅ Chunk 2 saved.\n",
            "✅ Chunk 3 saved.\n",
            "✅ Chunk 4 saved.\n",
            "✅ Chunk 5 saved.\n",
            "✅ Chunk 6 saved.\n",
            "✅ Chunk 7 saved.\n",
            "✅ Chunk 8 saved.\n",
            "✅ Chunk 9 saved.\n",
            "✅ Chunk 10 saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from lightgbm import LGBMRanker\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"train_enriched.csv\", nrows=400_000)  # Adjust as needed\n",
        "\n",
        "# === Define Feature Columns ===\n",
        "feature_cols = [\n",
        "    'price_usd_log', 'distance_log', 'prop_location_score1',\n",
        "    'prop_starrating', 'prop_review_score', 'prop_log_historical_price',\n",
        "    'srch_length_of_stay', 'srch_booking_window',\n",
        "    'srch_adults_count', 'srch_children_count',\n",
        "    'promotion_flag', 'star_diff', 'price_vs_hist',\n",
        "    'is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating',\n",
        "    'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff',\n",
        "    'is_null_orig_destination_distance',\n",
        "    'price_rank_pct', 'score1_rank_pct', 'review_score_rank_pct',\n",
        "    'price_vs_group_mean', 'score1_vs_group_mean', 'review_vs_group_mean',\n",
        "    'prop_ctr', 'prop_booking_rate'\n",
        "]\n",
        "\n",
        "# Add categoricals (LightGBM handles these natively)\n",
        "cat_cols = ['price_bucket', 'star_rating_bucket']\n",
        "feature_cols += cat_cols\n",
        "\n",
        "# === Prepare Inputs ===\n",
        "X = df[feature_cols]\n",
        "y = df['target']\n",
        "groups = df['srch_id']\n",
        "\n",
        "# === Encode categoricals (as category dtype for LightGBM) ===\n",
        "X[cat_cols] = X[cat_cols].astype('category')\n",
        "\n",
        "# === GroupKFold CV ===\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
        "    print(f\"\\n🧪 Fold {fold+1} training...\")\n",
        "\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "    group_train = X_train.groupby(groups.iloc[train_idx]).size().values\n",
        "    group_val = X_val.groupby(groups.iloc[val_idx]).size().values\n",
        "\n",
        "    model = LGBMRanker(\n",
        "        objective='lambdarank',\n",
        "        metric='ndcg',\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=300,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        group=group_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_group=[group_val],\n",
        "        eval_at=[5],\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=15),\n",
        "            log_evaluation(period=10)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Fold {fold+1} done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8duh1M_Vg6K",
        "outputId": "a0787973-97ff-4e26-8d33-f761513c1b56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d08ee7d5dd2c>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[cat_cols] = X[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Fold 1 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048998 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3794\n",
            "[LightGBM] [Info] Number of data points in the train set: 319996, number of used features: 28\n",
            "Training until validation scores don't improve for 15 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.395299\n",
            "[20]\tvalid_0's ndcg@5: 0.399812\n",
            "[30]\tvalid_0's ndcg@5: 0.403024\n",
            "[40]\tvalid_0's ndcg@5: 0.401661\n",
            "[50]\tvalid_0's ndcg@5: 0.403408\n",
            "[60]\tvalid_0's ndcg@5: 0.403645\n",
            "Early stopping, best iteration is:\n",
            "[52]\tvalid_0's ndcg@5: 0.405517\n",
            "✅ Fold 1 done.\n",
            "\n",
            "🧪 Fold 2 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084537 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3794\n",
            "[LightGBM] [Info] Number of data points in the train set: 320001, number of used features: 28\n",
            "Training until validation scores don't improve for 15 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.401143\n",
            "[20]\tvalid_0's ndcg@5: 0.403541\n",
            "[30]\tvalid_0's ndcg@5: 0.403284\n",
            "[40]\tvalid_0's ndcg@5: 0.403566\n",
            "[50]\tvalid_0's ndcg@5: 0.403709\n",
            "[60]\tvalid_0's ndcg@5: 0.407253\n",
            "[70]\tvalid_0's ndcg@5: 0.409009\n",
            "[80]\tvalid_0's ndcg@5: 0.409085\n",
            "[90]\tvalid_0's ndcg@5: 0.408874\n",
            "[100]\tvalid_0's ndcg@5: 0.41108\n",
            "[110]\tvalid_0's ndcg@5: 0.412233\n",
            "[120]\tvalid_0's ndcg@5: 0.411918\n",
            "[130]\tvalid_0's ndcg@5: 0.413045\n",
            "[140]\tvalid_0's ndcg@5: 0.412697\n",
            "Early stopping, best iteration is:\n",
            "[127]\tvalid_0's ndcg@5: 0.413859\n",
            "✅ Fold 2 done.\n",
            "\n",
            "🧪 Fold 3 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3788\n",
            "[LightGBM] [Info] Number of data points in the train set: 320001, number of used features: 28\n",
            "Training until validation scores don't improve for 15 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.399278\n",
            "[20]\tvalid_0's ndcg@5: 0.405964\n",
            "[30]\tvalid_0's ndcg@5: 0.406598\n",
            "[40]\tvalid_0's ndcg@5: 0.408269\n",
            "[50]\tvalid_0's ndcg@5: 0.407923\n",
            "Early stopping, best iteration is:\n",
            "[43]\tvalid_0's ndcg@5: 0.410737\n",
            "✅ Fold 3 done.\n",
            "\n",
            "🧪 Fold 4 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3785\n",
            "[LightGBM] [Info] Number of data points in the train set: 320001, number of used features: 28\n",
            "Training until validation scores don't improve for 15 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.40194\n",
            "[20]\tvalid_0's ndcg@5: 0.408322\n",
            "[30]\tvalid_0's ndcg@5: 0.410528\n",
            "[40]\tvalid_0's ndcg@5: 0.411808\n",
            "[50]\tvalid_0's ndcg@5: 0.413076\n",
            "Early stopping, best iteration is:\n",
            "[35]\tvalid_0's ndcg@5: 0.414968\n",
            "✅ Fold 4 done.\n",
            "\n",
            "🧪 Fold 5 training...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047839 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3787\n",
            "[LightGBM] [Info] Number of data points in the train set: 320001, number of used features: 28\n",
            "Training until validation scores don't improve for 15 rounds\n",
            "[10]\tvalid_0's ndcg@5: 0.388361\n",
            "[20]\tvalid_0's ndcg@5: 0.387444\n",
            "[30]\tvalid_0's ndcg@5: 0.388666\n",
            "Early stopping, best iteration is:\n",
            "[15]\tvalid_0's ndcg@5: 0.38957\n",
            "✅ Fold 5 done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, \"lightgbm_model.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VCqIuA-is8-",
        "outputId": "ba9c957f-8be0-4994-9c5d-eca190c9a8e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lightgbm_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model = joblib.load(\"lightgbm_model.joblib\")\n"
      ],
      "metadata": {
        "id": "dl4yjlWoil7g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# === Load the trained LightGBM model ===\n",
        "model = joblib.load(\"lightgbm_model.joblib\")\n",
        "\n",
        "# === Load prop-level CTR & booking rate ===\n",
        "prop_stats = pd.read_csv(\"train_enriched.csv\", usecols=['prop_id', 'prop_ctr', 'prop_booking_rate']).drop_duplicates('prop_id')\n",
        "\n",
        "# === Full list of 28 training features ===\n",
        "features = [\n",
        "    'price_usd_log', 'distance_log', 'prop_location_score1',\n",
        "    'prop_starrating', 'prop_review_score', 'prop_log_historical_price',\n",
        "    'srch_length_of_stay', 'srch_booking_window',\n",
        "    'srch_adults_count', 'srch_children_count',\n",
        "    'promotion_flag', 'star_diff', 'price_vs_hist',\n",
        "    'is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating',\n",
        "    'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff',\n",
        "    'is_null_orig_destination_distance',\n",
        "    'price_rank_pct', 'score1_rank_pct', 'review_score_rank_pct',\n",
        "    'price_vs_group_mean', 'score1_vs_group_mean', 'review_vs_group_mean',\n",
        "    'prop_ctr', 'prop_booking_rate',\n",
        "    'price_bucket', 'star_rating_bucket'\n",
        "]\n",
        "\n",
        "cat_cols = ['price_bucket', 'star_rating_bucket']\n",
        "\n",
        "# === Transformation Function for Each Chunk ===\n",
        "def prepare_test(df, prop_stats):\n",
        "    df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(-1)\n",
        "    df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(-1)\n",
        "    df['prop_review_score'] = df['prop_review_score'].fillna(df['prop_review_score'].median())\n",
        "    df['orig_destination_distance'] = df['orig_destination_distance'].fillna(df['orig_destination_distance'].median())\n",
        "    df['comp1_rate_percent_diff'] = df['comp1_rate_percent_diff'].fillna(-999)\n",
        "\n",
        "    for col in ['visitor_hist_adr_usd', 'visitor_hist_starrating', 'prop_review_score', 'comp1_rate_percent_diff', 'orig_destination_distance']:\n",
        "        df[f'is_null_{col}'] = df[col].isnull().astype(int)\n",
        "\n",
        "    df['price_usd_log'] = np.log1p(df['price_usd'])\n",
        "    df['distance_log'] = np.log1p(df['orig_destination_distance'])\n",
        "    df['price_vs_hist'] = df['price_usd'] - df['visitor_hist_adr_usd']\n",
        "    df['star_diff'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
        "\n",
        "    df['price_rank_pct'] = df.groupby('srch_id')['price_usd'].rank(pct=True)\n",
        "    df['score1_rank_pct'] = df.groupby('srch_id')['prop_location_score1'].rank(pct=True)\n",
        "    df['review_score_rank_pct'] = df.groupby('srch_id')['prop_review_score'].rank(pct=True)\n",
        "    df['price_vs_group_mean'] = df['price_usd'] - df.groupby('srch_id')['price_usd'].transform('mean')\n",
        "    df['score1_vs_group_mean'] = df['prop_location_score1'] - df.groupby('srch_id')['prop_location_score1'].transform('mean')\n",
        "    df['review_vs_group_mean'] = df['prop_review_score'] - df.groupby('srch_id')['prop_review_score'].transform('mean')\n",
        "\n",
        "    df['price_bucket'] = pd.cut(df['price_usd_log'], [-np.inf, 4.5, 5.5, np.inf], labels=['low', 'medium', 'high'])\n",
        "    df['star_rating_bucket'] = pd.cut(df['prop_starrating'], [0, 2, 3.5, 5], labels=['economy', 'standard', 'premium'])\n",
        "\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
        "    df = df.merge(prop_stats, on='prop_id', how='left')\n",
        "\n",
        "    df[cat_cols] = df[cat_cols].astype('category')\n",
        "    return df\n",
        "\n",
        "# === Chunked Prediction ===\n",
        "chunksize = 100_000\n",
        "reader = pd.read_csv(\"/content/data/test_set_VU_DM.csv\", chunksize=chunksize)\n",
        "submission_parts = []\n",
        "\n",
        "for i, chunk in enumerate(reader):\n",
        "    print(f\"🔄 Processing chunk {i+1}...\")\n",
        "    chunk = prepare_test(chunk, prop_stats)\n",
        "\n",
        "    # Ensure all 28 features exist (fill if missing due to dummies)\n",
        "    for col in features:\n",
        "        if col not in chunk.columns:\n",
        "            chunk[col] = 0\n",
        "\n",
        "    # Save ID columns before narrowing the feature list\n",
        "    chunk_ids = chunk[['srch_id', 'prop_id']].copy()\n",
        "\n",
        "    # Prepare only model features\n",
        "    chunk_model_input = chunk[features]\n",
        "    chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n",
        "\n",
        "    # Predict scores\n",
        "    chunk_ids['score'] = model.predict(chunk_model_input)\n",
        "\n",
        "    sorted_chunk = chunk_ids.sort_values(['srch_id', 'score'], ascending=[True, False])[['srch_id', 'prop_id']]\n",
        "    submission_parts.append(sorted_chunk)\n",
        "\n",
        "# === Final submission\n",
        "submission = pd.concat(submission_parts, ignore_index=True)\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Submission saved as submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RaQCqNKVlkW",
        "outputId": "68f430ec-7b3e-4d7f-e8e1-470e864d850c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 13...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 14...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 15...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 17...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 18...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 21...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 22...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 23...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 24...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 25...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 26...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 27...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 28...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 29...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 30...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 31...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 32...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 33...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 34...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 35...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 36...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 37...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 38...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 39...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 40...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 41...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 42...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 43...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 44...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 45...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 46...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 47...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 48...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 49...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 50...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a20203f7982e>:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk_model_input[cat_cols] = chunk_model_input[cat_cols].astype('category')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission saved as submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"submission.csv\")\n",
        "# Should show True if sorted properly\n",
        "check = df.groupby('srch_id').cumcount().eq(0).all()\n",
        "print(\"✅ Each srch_id starts with top-ranked prop_id:\", check)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBV01I8MdiCp",
        "outputId": "dc6f6ec2-a42e-4260-b5d4-db86134ef474"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Each srch_id starts with top-ranked prop_id: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# === Load trained model and property-level stats ===\n",
        "model = joblib.load(\"lightgbm_model.joblib\")\n",
        "prop_stats = pd.read_csv(\"train_enriched.csv\", usecols=['prop_id', 'prop_ctr', 'prop_booking_rate']).drop_duplicates('prop_id')\n",
        "\n",
        "# === Feature list used during training (28 total) ===\n",
        "features = [\n",
        "    'price_usd_log', 'distance_log', 'prop_location_score1',\n",
        "    'prop_starrating', 'prop_review_score', 'prop_log_historical_price',\n",
        "    'srch_length_of_stay', 'srch_booking_window',\n",
        "    'srch_adults_count', 'srch_children_count',\n",
        "    'promotion_flag', 'star_diff', 'price_vs_hist',\n",
        "    'is_null_visitor_hist_adr_usd', 'is_null_visitor_hist_starrating',\n",
        "    'is_null_prop_review_score', 'is_null_comp1_rate_percent_diff',\n",
        "    'is_null_orig_destination_distance',\n",
        "    'price_rank_pct', 'score1_rank_pct', 'review_score_rank_pct',\n",
        "    'price_vs_group_mean', 'score1_vs_group_mean', 'review_vs_group_mean',\n",
        "    'prop_ctr', 'prop_booking_rate',\n",
        "    'price_bucket', 'star_rating_bucket'\n",
        "]\n",
        "cat_cols = ['price_bucket', 'star_rating_bucket']\n",
        "\n",
        "# === Preprocessing function applied to each chunk ===\n",
        "def prepare_test(df, prop_stats):\n",
        "    df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(-1)\n",
        "    df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(-1)\n",
        "    df['prop_review_score'] = df['prop_review_score'].fillna(df['prop_review_score'].median())\n",
        "    df['orig_destination_distance'] = df['orig_destination_distance'].fillna(df['orig_destination_distance'].median())\n",
        "    df['comp1_rate_percent_diff'] = df['comp1_rate_percent_diff'].fillna(-999)\n",
        "\n",
        "    for col in ['visitor_hist_adr_usd', 'visitor_hist_starrating', 'prop_review_score', 'comp1_rate_percent_diff', 'orig_destination_distance']:\n",
        "        df[f'is_null_{col}'] = df[col].isnull().astype(int)\n",
        "\n",
        "    df['price_usd_log'] = np.log1p(df['price_usd'])\n",
        "    df['distance_log'] = np.log1p(df['orig_destination_distance'])\n",
        "    df['price_vs_hist'] = df['price_usd'] - df['visitor_hist_adr_usd']\n",
        "    df['star_diff'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
        "\n",
        "    df['price_rank_pct'] = df.groupby('srch_id')['price_usd'].rank(pct=True)\n",
        "    df['score1_rank_pct'] = df.groupby('srch_id')['prop_location_score1'].rank(pct=True)\n",
        "    df['review_score_rank_pct'] = df.groupby('srch_id')['prop_review_score'].rank(pct=True)\n",
        "    df['price_vs_group_mean'] = df['price_usd'] - df.groupby('srch_id')['price_usd'].transform('mean')\n",
        "    df['score1_vs_group_mean'] = df['prop_location_score1'] - df.groupby('srch_id')['prop_location_score1'].transform('mean')\n",
        "    df['review_vs_group_mean'] = df['prop_review_score'] - df.groupby('srch_id')['prop_review_score'].transform('mean')\n",
        "\n",
        "    df['price_bucket'] = pd.cut(df['price_usd_log'], [-np.inf, 4.5, 5.5, np.inf], labels=['low', 'medium', 'high'])\n",
        "    df['star_rating_bucket'] = pd.cut(df['prop_starrating'], [0, 2, 3.5, 5], labels=['economy', 'standard', 'premium'])\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
        "\n",
        "    df = df.merge(prop_stats, on='prop_id', how='left')\n",
        "    df[cat_cols] = df[cat_cols].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Process test file in chunks and predict scores ===\n",
        "submission_parts = []\n",
        "chunksize = 100_000\n",
        "reader = pd.read_csv(\"/content/data/test_set_VU_DM.csv\", chunksize=chunksize)\n",
        "\n",
        "for i, chunk in enumerate(reader):\n",
        "    print(f\"🔄 Processing chunk {i+1}...\")\n",
        "    chunk = prepare_test(chunk, prop_stats)\n",
        "\n",
        "    # Align columns\n",
        "    for col in features:\n",
        "        if col not in chunk.columns:\n",
        "            chunk[col] = 0\n",
        "\n",
        "    # Save original IDs\n",
        "    chunk_ids = chunk[['srch_id', 'prop_id']].copy()\n",
        "\n",
        "    # Predict\n",
        "    chunk_model_input = chunk[features]\n",
        "    chunk_model_input.loc[:, cat_cols] = chunk_model_input[cat_cols].astype('category')\n",
        "    chunk_ids['score'] = model.predict(chunk_model_input)\n",
        "\n",
        "    # Append for later global sort\n",
        "    submission_parts.append(chunk_ids)\n",
        "\n",
        "# === Combine and globally sort\n",
        "submission = pd.concat(submission_parts, ignore_index=True)\n",
        "\n",
        "# Sort each srch_id group by score descending\n",
        "submission = (\n",
        "    submission\n",
        "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Final check before dropping score\n",
        "check = submission.groupby('srch_id')['score'].apply(lambda x: x.iloc[0] == x.max()).all()\n",
        "print(\"✅ Each srch_id top row has highest score:\", check)\n",
        "\n",
        "# Now safely drop score and save\n",
        "submission = submission[['srch_id', 'prop_id']]\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"📦 Cleaned submission.csv saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df0BPRgNuezs",
        "outputId": "f62f415a-8d46-466d-e576-d33898ab6274"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Processing chunk 1...\n",
            "🔄 Processing chunk 2...\n",
            "🔄 Processing chunk 3...\n",
            "🔄 Processing chunk 4...\n",
            "🔄 Processing chunk 5...\n",
            "🔄 Processing chunk 6...\n",
            "🔄 Processing chunk 7...\n",
            "🔄 Processing chunk 8...\n",
            "🔄 Processing chunk 9...\n",
            "🔄 Processing chunk 10...\n",
            "🔄 Processing chunk 11...\n",
            "🔄 Processing chunk 12...\n",
            "🔄 Processing chunk 13...\n",
            "🔄 Processing chunk 14...\n",
            "🔄 Processing chunk 15...\n",
            "🔄 Processing chunk 16...\n",
            "🔄 Processing chunk 17...\n",
            "🔄 Processing chunk 18...\n",
            "🔄 Processing chunk 19...\n",
            "🔄 Processing chunk 20...\n",
            "🔄 Processing chunk 21...\n",
            "🔄 Processing chunk 22...\n",
            "🔄 Processing chunk 23...\n",
            "🔄 Processing chunk 24...\n",
            "🔄 Processing chunk 25...\n",
            "🔄 Processing chunk 26...\n",
            "🔄 Processing chunk 27...\n",
            "🔄 Processing chunk 28...\n",
            "🔄 Processing chunk 29...\n",
            "🔄 Processing chunk 30...\n",
            "🔄 Processing chunk 31...\n",
            "🔄 Processing chunk 32...\n",
            "🔄 Processing chunk 33...\n",
            "🔄 Processing chunk 34...\n",
            "🔄 Processing chunk 35...\n",
            "🔄 Processing chunk 36...\n",
            "🔄 Processing chunk 37...\n",
            "🔄 Processing chunk 38...\n",
            "🔄 Processing chunk 39...\n",
            "🔄 Processing chunk 40...\n",
            "🔄 Processing chunk 41...\n",
            "🔄 Processing chunk 42...\n",
            "🔄 Processing chunk 43...\n",
            "🔄 Processing chunk 44...\n",
            "🔄 Processing chunk 45...\n",
            "🔄 Processing chunk 46...\n",
            "🔄 Processing chunk 47...\n",
            "🔄 Processing chunk 48...\n",
            "🔄 Processing chunk 49...\n",
            "🔄 Processing chunk 50...\n",
            "✅ Each srch_id top row has highest score: True\n",
            "📦 Cleaned submission.csv saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXJYwGu4uszF"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}