{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Columns to drop (sparsity > 80%)\n",
    "DROPPED_COLS = [\n",
    "    'comp1_rate_percent_diff', 'comp6_rate_percent_diff', 'comp1_rate', 'comp1_inv',\n",
    "    'comp4_rate_percent_diff', 'gross_bookings_usd', 'comp7_rate_percent_diff',\n",
    "    'comp6_rate', 'visitor_hist_starrating', 'visitor_hist_adr_usd',\n",
    "    'comp6_inv', 'comp4_rate', 'comp7_rate', 'srch_query_affinity_score',\n",
    "    'comp4_inv', 'comp7_inv', 'comp3_rate_percent_diff', 'comp2_rate_percent_diff',\n",
    "    'comp8_rate_percent_diff', 'comp5_rate_percent_diff'\n",
    "]\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]: return 'winter'\n",
    "    elif month in [3, 4, 5]: return 'spring'\n",
    "    elif month in [6, 7, 8]: return 'summer'\n",
    "    return 'fall'\n",
    "\n",
    "def prepare_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop sparse columns\n",
    "    df.drop(columns=DROPPED_COLS, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Parse datetime and extract components\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n",
    "    df['year'] = df['date_time'].dt.year\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    \n",
    "    # Map season to ordinal (optional)\n",
    "    df['season'] = df['season'].map({'winter': 0, 'spring': 1, 'summer': 2, 'fall': 3})\n",
    "\n",
    "    # Impute prop_review_score with 0\n",
    "    df['prop_review_score'].fillna(0, inplace=True)\n",
    "\n",
    "    # Impute prop_location_score2 using known values\n",
    "    if 'prop_location_score2' in df.columns:\n",
    "        score2_lookup = df[['prop_id', 'prop_location_score2']].dropna().drop_duplicates('prop_id').set_index('prop_id')['prop_location_score2']\n",
    "        df['prop_location_score2'] = df.apply(\n",
    "            lambda row: score2_lookup[row['prop_id']]\n",
    "            if pd.isnull(row['prop_location_score2']) and row['prop_id'] in score2_lookup\n",
    "            else row['prop_location_score2'],\n",
    "            axis=1\n",
    "        )\n",
    "        df['prop_location_score2'].fillna(0, inplace=True)\n",
    "\n",
    "    # Impute orig_destination_distance\n",
    "    df['orig_distance_missing'] = df['orig_destination_distance'].isnull().astype(int)\n",
    "    df['orig_destination_distance'].fillna(-1, inplace=True)\n",
    "\n",
    "    # Remove target variables from train when preparing features\n",
    "    if is_train:\n",
    "        target_cols = ['booking_bool', 'click_bool', 'position', 'gross_bookings_usd']\n",
    "        features = [col for col in df.columns if col not in target_cols]\n",
    "        X = df[features]\n",
    "        y = df['booking_bool']\n",
    "        return X, y\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_review_score'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_location_score2'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['orig_destination_distance'].fillna(-1, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_review_score'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_location_score2'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['orig_destination_distance'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "X_train, y_train = prepare_data(train, is_train=True)\n",
    "\n",
    "# Prepare test data\n",
    "X_test = prepare_data(test, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: train_features.csv, train_labels.csv, test_features.csv\n"
     ]
    }
   ],
   "source": [
    "# === Save cleaned versions ===\n",
    "X_train.to_csv(\"train_features.csv\", index=False)\n",
    "y_train.to_csv(\"train_labels.csv\", index=False)\n",
    "X_test.to_csv(\"test_features.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved: train_features.csv, train_labels.csv, test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_review_score'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_location_score2'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['orig_destination_distance'].fillna(-1, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_review_score'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['prop_location_score2'].fillna(0, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/1989517866.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['orig_destination_distance'].fillna(-1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_train shape: (4958347, 39)\n",
      "✅ X_test shape:  (4959183, 39)\n",
      "🎯 y_train shape: (4958347,)\n",
      "\n",
      "=== Missing values per column in X_train ===\n",
      "comp2_rate    2933675\n",
      "comp2_inv     2828078\n",
      "comp3_rate    3424059\n",
      "comp3_inv     3307357\n",
      "comp5_rate    2735974\n",
      "comp5_inv     2598327\n",
      "comp8_rate    3041693\n",
      "comp8_inv     2970844\n",
      "dtype: int64\n",
      "\n",
      "=== Missing values per column in X_test ===\n",
      "comp2_rate    2943222\n",
      "comp2_inv     2837914\n",
      "comp3_rate    3434198\n",
      "comp3_inv     3317952\n",
      "comp5_rate    2737262\n",
      "comp5_inv     2598370\n",
      "comp8_rate    3056794\n",
      "comp8_inv     2986298\n",
      "dtype: int64\n",
      "\n",
      "=== Object-type columns in X_train ===\n",
      "[]\n",
      "\n",
      "=== Object-type columns in X_test ===\n",
      "[]\n",
      "\n",
      "✅ Columns match between train/test: True\n"
     ]
    }
   ],
   "source": [
    "# Assume prepare_data has already been called\n",
    "X_train, y_train = prepare_data(train, is_train=True)\n",
    "X_test = prepare_data(test, is_train=False)\n",
    "\n",
    "# === 1. Check shape and preview ===\n",
    "print(f\"✅ X_train shape: {X_train.shape}\")\n",
    "print(f\"✅ X_test shape:  {X_test.shape}\")\n",
    "print(f\"🎯 y_train shape: {y_train.shape}\")\n",
    "\n",
    "# === 2. Check for NaNs ===\n",
    "print(\"\\n=== Missing values per column in X_train ===\")\n",
    "print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\n=== Missing values per column in X_test ===\")\n",
    "print(X_test.isnull().sum()[X_test.isnull().sum() > 0])\n",
    "\n",
    "# === 3. Check for object dtype leftovers ===\n",
    "print(\"\\n=== Object-type columns in X_train ===\")\n",
    "print(X_train.select_dtypes(include=['object']).columns.tolist())\n",
    "\n",
    "print(\"\\n=== Object-type columns in X_test ===\")\n",
    "print(X_test.select_dtypes(include=['object']).columns.tolist())\n",
    "\n",
    "# === 4. Confirm column match ===\n",
    "train_cols = set(X_train.columns)\n",
    "test_cols = set(X_test.columns)\n",
    "print(\"\\n✅ Columns match between train/test:\", train_cols == test_cols)\n",
    "\n",
    "if train_cols != test_cols:\n",
    "    print(\"❌ Difference:\", train_cols.symmetric_difference(test_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sparse competitor columns with known missing values\n",
    "sparse_cols = [\n",
    "    'comp2_rate', 'comp2_inv',\n",
    "    'comp3_rate', 'comp3_inv',\n",
    "    'comp5_rate', 'comp5_inv',\n",
    "    'comp8_rate', 'comp8_inv'\n",
    "]\n",
    "\n",
    "# Add missing value indicator columns (1 = missing, 0 = present)\n",
    "for col in sparse_cols:\n",
    "    X_train[f'{col}_missing'] = X_train[col].isnull().astype(int)\n",
    "    X_test[f'{col}_missing'] = X_test[col].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_with_flags.csv\", index=False)\n",
    "y_train.to_csv(\"y_train.csv\", index=False)\n",
    "X_test.to_csv(\"X_test_with_flags.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['price_diff_vs_hist'] = X_train['price_usd'] - X_train['prop_log_historical_price']\n",
    "X_test['price_diff_vs_hist'] = X_test['price_usd'] - X_test['prop_log_historical_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['price_rank'] = X_train.groupby('srch_id')['price_usd'].rank(method='min')\n",
    "X_test['price_rank'] = X_test.groupby('srch_id')['price_usd'].rank(method='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['review_rank'] = X_train.groupby('srch_id')['prop_review_score'].rank(method='min')\n",
    "X_test['review_rank'] = X_test.groupby('srch_id')['prop_review_score'].rank(method='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_star_rating(rating):\n",
    "    if rating < 2.5:\n",
    "        return 0  # low-tier\n",
    "    elif rating < 4:\n",
    "        return 1  # mid-tier\n",
    "    else:\n",
    "        return 2  # high-tier\n",
    "\n",
    "X_train['star_rating_bucket'] = X_train['prop_starrating'].apply(bucket_star_rating)\n",
    "X_test['star_rating_bucket'] = X_test['prop_starrating'].apply(bucket_star_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_train['star_rating_bucket'] = le.fit_transform(X_train['star_rating_bucket'])\n",
    "X_test['star_rating_bucket'] = le.transform(X_test['star_rating_bucket'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/376711895.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['prop_booking_rate'].fillna(global_booking_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Compute booking rate from training data\n",
    "booking_rate = train.groupby('prop_id')['booking_bool'].mean()\n",
    "\n",
    "# Map it to both train and test\n",
    "X_train['prop_booking_rate'] = X_train['prop_id'].map(booking_rate)\n",
    "X_test['prop_booking_rate'] = X_test['prop_id'].map(booking_rate)\n",
    "\n",
    "# Fill unknown properties in test with global mean\n",
    "global_booking_mean = train['booking_bool'].mean()\n",
    "X_test['prop_booking_rate'].fillna(global_booking_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['location_score_ratio'] = X_train['prop_location_score1'] / (X_train['prop_location_score2'] + 1e-5)\n",
    "X_test['location_score_ratio'] = X_test['prop_location_score1'] / (X_test['prop_location_score2'] + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Final Check: Missing Values in X_train\n",
      "comp3_rate    3424059\n",
      "comp3_inv     3307357\n",
      "comp8_rate    3041693\n",
      "comp8_inv     2970844\n",
      "comp2_rate    2933675\n",
      "comp2_inv     2828078\n",
      "comp5_rate    2735974\n",
      "comp5_inv     2598327\n",
      "dtype: int64\n",
      "\n",
      "🔍 Final Check: Missing Values in X_test\n",
      "comp3_rate    3434198\n",
      "comp3_inv     3317952\n",
      "comp8_rate    3056794\n",
      "comp8_inv     2986298\n",
      "comp2_rate    2943222\n",
      "comp2_inv     2837914\n",
      "comp5_rate    2737262\n",
      "comp5_inv     2598370\n",
      "dtype: int64\n",
      "\n",
      "🧠 Columns with dtype 'object' in X_train:\n",
      "[]\n",
      "\n",
      "🧠 Columns with dtype 'object' in X_test:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Final Check: Missing Values in X_train\")\n",
    "missing_train = X_train.isnull().sum()\n",
    "print(missing_train[missing_train > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n🔍 Final Check: Missing Values in X_test\")\n",
    "missing_test = X_test.isnull().sum()\n",
    "print(missing_test[missing_test > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n🧠 Columns with dtype 'object' in X_train:\")\n",
    "print(X_train.select_dtypes(include='object').columns.tolist())\n",
    "\n",
    "print(\"\\n🧠 Columns with dtype 'object' in X_test:\")\n",
    "print(X_test.select_dtypes(include='object').columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Imputing: comp2_rate\n",
      "\n",
      "🔄 Imputing: comp2_inv\n",
      "\n",
      "🔄 Imputing: comp3_rate\n",
      "\n",
      "🔄 Imputing: comp3_inv\n",
      "\n",
      "🔄 Imputing: comp5_rate\n",
      "\n",
      "🔄 Imputing: comp5_inv\n",
      "\n",
      "🔄 Imputing: comp8_rate\n",
      "\n",
      "🔄 Imputing: comp8_inv\n"
     ]
    }
   ],
   "source": [
    "# Competitor columns to fill\n",
    "comp_cols = [\n",
    "    'comp2_rate', 'comp2_inv',\n",
    "    'comp3_rate', 'comp3_inv',\n",
    "    'comp5_rate', 'comp5_inv',\n",
    "    'comp8_rate', 'comp8_inv'\n",
    "]\n",
    "\n",
    "for col in comp_cols:\n",
    "    print(f\"\\n🔄 Imputing: {col}\")\n",
    "    \n",
    "    # Step 1: compute mean per group (from X_train only)\n",
    "    group_means = X_train.groupby('srch_destination_id')[col].mean()\n",
    "\n",
    "    # Step 2: fallback value (global mean, can also use 0 if preferred)\n",
    "    global_mean = X_train[col].mean()\n",
    "    \n",
    "    # Step 3: apply to train\n",
    "    X_train[col] = X_train.apply(\n",
    "        lambda row: group_means.get(row['srch_destination_id'], global_mean)\n",
    "        if pd.isnull(row[col]) else row[col],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Step 4: apply to test\n",
    "    X_test[col] = X_test.apply(\n",
    "        lambda row: group_means.get(row['srch_destination_id'], global_mean)\n",
    "        if pd.isnull(row[col]) else row[col],\n",
    "        axis=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Post-Imputation Check\n",
      "comp2_rate     829747\n",
      "comp2_inv      805772\n",
      "comp3_rate     782746\n",
      "comp3_inv      751390\n",
      "comp5_rate     245083\n",
      "comp5_inv      230210\n",
      "comp8_rate    1033198\n",
      "comp8_inv     1018927\n",
      "dtype: int64\n",
      "comp2_rate    760936\n",
      "comp2_inv     736525\n",
      "comp3_rate    708357\n",
      "comp3_inv     678913\n",
      "comp5_rate    204110\n",
      "comp5_inv     189586\n",
      "comp8_rate    948855\n",
      "comp8_inv     935236\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ Post-Imputation Check\")\n",
    "print(X_train[comp_cols].isnull().sum())\n",
    "print(X_test[comp_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/2719154085.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(global_mean, inplace=True)\n",
      "/var/folders/9b/27c0j34x4f10cr19hc97p2lh0000gn/T/ipykernel_51303/2719154085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(global_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in comp_cols:\n",
    "    global_mean = X_train[col].mean()\n",
    "    X_train[col].fillna(global_mean, inplace=True)\n",
    "    X_test[col].fillna(global_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Missing Check\n",
      "comp2_rate    0\n",
      "comp2_inv     0\n",
      "comp3_rate    0\n",
      "comp3_inv     0\n",
      "comp5_rate    0\n",
      "comp5_inv     0\n",
      "comp8_rate    0\n",
      "comp8_inv     0\n",
      "dtype: int64\n",
      "comp2_rate    0\n",
      "comp2_inv     0\n",
      "comp3_rate    0\n",
      "comp3_inv     0\n",
      "comp5_rate    0\n",
      "comp5_inv     0\n",
      "comp8_rate    0\n",
      "comp8_inv     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ Final Missing Check\")\n",
    "print(X_train[comp_cols].isnull().sum())\n",
    "print(X_test[comp_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_final.csv\", index=False)\n",
    "y_train.to_csv(\"y_train_final.csv\", index=False)\n",
    "X_test.to_csv(\"X_test_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>...</th>\n",
       "      <th>comp5_rate_missing</th>\n",
       "      <th>comp5_inv_missing</th>\n",
       "      <th>comp8_rate_missing</th>\n",
       "      <th>comp8_inv_missing</th>\n",
       "      <th>price_diff_vs_hist</th>\n",
       "      <th>price_rank</th>\n",
       "      <th>review_rank</th>\n",
       "      <th>star_rating_bucket</th>\n",
       "      <th>prop_booking_rate</th>\n",
       "      <th>location_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.82</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>64.597124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.71</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>147.551979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.88</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>89.759282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598.38</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>226.219025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138.65</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036090</td>\n",
       "      <td>21.271453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>30184</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190.12</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>21.273328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>44147</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.54</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.780399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>50984</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>161000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>53341</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.87</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.088272</td>\n",
       "      <td>20.676844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>56880</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275.54</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038519</td>\n",
       "      <td>27.526505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>59267</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185.06</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>220000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>59526</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041076</td>\n",
       "      <td>58.339963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>68914</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>106.744299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>74474</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205.81</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>19.121982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>81437</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.37</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>148.291425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>85728</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>248.266297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>88096</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147.45</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>44.538706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>88127</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.60</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>364.829396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>88218</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.063536</td>\n",
       "      <td>21.878209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>89073</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>138.574284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    srch_id           date_time  site_id  visitor_location_country_id  \\\n",
       "0         1 2013-04-04 08:32:15       12                          187   \n",
       "1         1 2013-04-04 08:32:15       12                          187   \n",
       "2         1 2013-04-04 08:32:15       12                          187   \n",
       "3         1 2013-04-04 08:32:15       12                          187   \n",
       "4         1 2013-04-04 08:32:15       12                          187   \n",
       "5         1 2013-04-04 08:32:15       12                          187   \n",
       "6         1 2013-04-04 08:32:15       12                          187   \n",
       "7         1 2013-04-04 08:32:15       12                          187   \n",
       "8         1 2013-04-04 08:32:15       12                          187   \n",
       "9         1 2013-04-04 08:32:15       12                          187   \n",
       "10        1 2013-04-04 08:32:15       12                          187   \n",
       "11        1 2013-04-04 08:32:15       12                          187   \n",
       "12        1 2013-04-04 08:32:15       12                          187   \n",
       "13        1 2013-04-04 08:32:15       12                          187   \n",
       "14        1 2013-04-04 08:32:15       12                          187   \n",
       "15        1 2013-04-04 08:32:15       12                          187   \n",
       "16        1 2013-04-04 08:32:15       12                          187   \n",
       "17        1 2013-04-04 08:32:15       12                          187   \n",
       "18        1 2013-04-04 08:32:15       12                          187   \n",
       "19        1 2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "    prop_country_id  prop_id  prop_starrating  prop_review_score  \\\n",
       "0               219      893                3                3.5   \n",
       "1               219    10404                4                4.0   \n",
       "2               219    21315                3                4.5   \n",
       "3               219    27348                2                4.0   \n",
       "4               219    29604                4                3.5   \n",
       "5               219    30184                4                4.5   \n",
       "6               219    44147                3                3.5   \n",
       "7               219    50984                2                0.0   \n",
       "8               219    53341                4                4.0   \n",
       "9               219    56880                4                4.0   \n",
       "10              219    59267                3                0.0   \n",
       "11              219    59526                3                3.5   \n",
       "12              219    68914                2                3.0   \n",
       "13              219    74474                3                4.5   \n",
       "14              219    81437                3                4.0   \n",
       "15              219    85728                2                3.0   \n",
       "16              219    88096                4                4.0   \n",
       "17              219    88127                3                3.0   \n",
       "18              219    88218                4                3.5   \n",
       "19              219    89073                4                4.0   \n",
       "\n",
       "    prop_brand_bool  prop_location_score1  ...  comp5_rate_missing  \\\n",
       "0                 1                  2.83  ...                   0   \n",
       "1                 1                  2.20  ...                   0   \n",
       "2                 1                  2.20  ...                   0   \n",
       "3                 1                  2.83  ...                   0   \n",
       "4                 1                  2.64  ...                   0   \n",
       "5                 1                  2.77  ...                   0   \n",
       "6                 1                  2.20  ...                   1   \n",
       "7                 0                  1.61  ...                   1   \n",
       "8                 1                  2.56  ...                   1   \n",
       "9                 1                  2.83  ...                   0   \n",
       "10                1                  2.20  ...                   1   \n",
       "11                0                  2.20  ...                   1   \n",
       "12                1                  2.20  ...                   0   \n",
       "13                1                  2.40  ...                   0   \n",
       "14                1                  2.30  ...                   0   \n",
       "15                1                  1.79  ...                   0   \n",
       "16                1                  2.94  ...                   0   \n",
       "17                1                  1.39  ...                   1   \n",
       "18                1                  2.77  ...                   0   \n",
       "19                1                  2.08  ...                   0   \n",
       "\n",
       "    comp5_inv_missing  comp8_rate_missing  comp8_inv_missing  \\\n",
       "0                   0                   0                  0   \n",
       "1                   0                   0                  0   \n",
       "2                   0                   0                  0   \n",
       "3                   0                   0                  0   \n",
       "4                   0                   0                  0   \n",
       "5                   0                   0                  0   \n",
       "6                   1                   0                  0   \n",
       "7                   1                   1                  1   \n",
       "8                   1                   0                  0   \n",
       "9                   0                   0                  0   \n",
       "10                  1                   0                  0   \n",
       "11                  1                   0                  0   \n",
       "12                  0                   0                  0   \n",
       "13                  0                   0                  0   \n",
       "14                  0                   0                  0   \n",
       "15                  0                   0                  0   \n",
       "16                  0                   0                  0   \n",
       "17                  1                   0                  0   \n",
       "18                  0                   0                  0   \n",
       "19                  0                   0                  0   \n",
       "\n",
       "    price_diff_vs_hist  price_rank  review_rank  star_rating_bucket  \\\n",
       "0                99.82         5.0          7.0                   1   \n",
       "1               165.71        19.0         16.0                   2   \n",
       "2               174.88        20.0         24.0                   1   \n",
       "3               598.38        28.0         16.0                   0   \n",
       "4               138.65        16.0          7.0                   2   \n",
       "5               190.12        25.0         24.0                   2   \n",
       "6               124.54        12.0          7.0                   1   \n",
       "7                81.23         1.0          1.0                   0   \n",
       "8               144.87        17.0         16.0                   2   \n",
       "9               275.54        27.0         16.0                   2   \n",
       "10              185.06        22.0          1.0                   1   \n",
       "11               96.11         2.0          7.0                   1   \n",
       "12               96.45         2.0          4.0                   0   \n",
       "13              205.81        26.0         24.0                   1   \n",
       "14              133.37        13.0         16.0                   1   \n",
       "15               96.39         2.0          4.0                   0   \n",
       "16              147.45        18.0         16.0                   2   \n",
       "17              133.60        13.0          4.0                   1   \n",
       "18              110.14         7.0          7.0                   2   \n",
       "19              186.16        24.0         16.0                   2   \n",
       "\n",
       "    prop_booking_rate  location_score_ratio  \n",
       "0            0.016340             64.597124  \n",
       "1            0.015437            147.551979  \n",
       "2            0.003630             89.759282  \n",
       "3            0.013043            226.219025  \n",
       "4            0.036090             21.271453  \n",
       "5            0.021773             21.273328  \n",
       "6            0.000000             61.780399  \n",
       "7            0.019231         161000.000000  \n",
       "8            0.088272             20.676844  \n",
       "9            0.038519             27.526505  \n",
       "10           0.014881         220000.000000  \n",
       "11           0.041076             58.339963  \n",
       "12           0.029110            106.744299  \n",
       "13           0.030351             19.121982  \n",
       "14           0.022491            148.291425  \n",
       "15           0.007018            248.266297  \n",
       "16           0.054449             44.538706  \n",
       "17           0.007194            364.829396  \n",
       "18           0.063536             21.878209  \n",
       "19           0.031596            138.574284  \n",
       "\n",
       "[20 rows x 53 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>...</th>\n",
       "      <th>comp5_rate_missing</th>\n",
       "      <th>comp5_inv_missing</th>\n",
       "      <th>comp8_rate_missing</th>\n",
       "      <th>comp8_inv_missing</th>\n",
       "      <th>price_diff_vs_hist</th>\n",
       "      <th>price_rank</th>\n",
       "      <th>review_rank</th>\n",
       "      <th>star_rating_bucket</th>\n",
       "      <th>prop_booking_rate</th>\n",
       "      <th>location_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>3180</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113.97</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>42.540877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>5543</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113.07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>31.313012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>14142</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44.84</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>48.732242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>22393</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.97</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>42.773124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>24194</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>14.066313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>28181</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.47</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>12.595148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>34263</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>23.767403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>37567</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>204.923968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>50162</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45.63</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>27.224353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>54937</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.55</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050891</td>\n",
       "      <td>12.612940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>56050</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140.41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>22.890670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>61632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.365173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>61934</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027701</td>\n",
       "      <td>11.917034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>63894</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>12.250674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>72090</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>62.003862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>73666</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144.21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>12.719511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>74045</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>13.828566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>78599</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153.81</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>25.695453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>82231</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.08</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>13.252954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>89466</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.731783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    srch_id           date_time  site_id  visitor_location_country_id  \\\n",
       "0         1 2013-02-02 15:27:40       24                          216   \n",
       "1         1 2013-02-02 15:27:40       24                          216   \n",
       "2         1 2013-02-02 15:27:40       24                          216   \n",
       "3         1 2013-02-02 15:27:40       24                          216   \n",
       "4         1 2013-02-02 15:27:40       24                          216   \n",
       "5         1 2013-02-02 15:27:40       24                          216   \n",
       "6         1 2013-02-02 15:27:40       24                          216   \n",
       "7         1 2013-02-02 15:27:40       24                          216   \n",
       "8         1 2013-02-02 15:27:40       24                          216   \n",
       "9         1 2013-02-02 15:27:40       24                          216   \n",
       "10        1 2013-02-02 15:27:40       24                          216   \n",
       "11        1 2013-02-02 15:27:40       24                          216   \n",
       "12        1 2013-02-02 15:27:40       24                          216   \n",
       "13        1 2013-02-02 15:27:40       24                          216   \n",
       "14        1 2013-02-02 15:27:40       24                          216   \n",
       "15        1 2013-02-02 15:27:40       24                          216   \n",
       "16        1 2013-02-02 15:27:40       24                          216   \n",
       "17        1 2013-02-02 15:27:40       24                          216   \n",
       "18        1 2013-02-02 15:27:40       24                          216   \n",
       "19        1 2013-02-02 15:27:40       24                          216   \n",
       "\n",
       "    prop_country_id  prop_id  prop_starrating  prop_review_score  \\\n",
       "0               219     3180                3                4.5   \n",
       "1               219     5543                3                4.5   \n",
       "2               219    14142                2                3.5   \n",
       "3               219    22393                3                4.5   \n",
       "4               219    24194                3                4.5   \n",
       "5               219    28181                3                4.5   \n",
       "6               219    34263                3                4.5   \n",
       "7               219    37567                2                4.5   \n",
       "8               219    50162                2                3.5   \n",
       "9               219    54937                3                4.0   \n",
       "10              219    56050                3                4.0   \n",
       "11              219    61632                0                0.0   \n",
       "12              219    61934                3                4.5   \n",
       "13              219    63894                3                4.5   \n",
       "14              219    72090                3                4.0   \n",
       "15              219    73666                3                4.5   \n",
       "16              219    74045                3                4.0   \n",
       "17              219    78599                4                4.5   \n",
       "18              219    82231                3                4.5   \n",
       "19              219    89466                2                3.0   \n",
       "\n",
       "    prop_brand_bool  prop_location_score1  ...  comp5_rate_missing  \\\n",
       "0                 1                  2.94  ...                   1   \n",
       "1                 1                  2.64  ...                   1   \n",
       "2                 1                  2.71  ...                   0   \n",
       "3                 1                  2.40  ...                   0   \n",
       "4                 1                  2.94  ...                   0   \n",
       "5                 1                  2.30  ...                   1   \n",
       "6                 1                  3.09  ...                   0   \n",
       "7                 0                  2.83  ...                   0   \n",
       "8                 1                  2.20  ...                   0   \n",
       "9                 1                  2.08  ...                   0   \n",
       "10                1                  2.77  ...                   1   \n",
       "11                0                  3.04  ...                   1   \n",
       "12                1                  2.89  ...                   1   \n",
       "13                1                  2.77  ...                   0   \n",
       "14                1                  2.89  ...                   0   \n",
       "15                1                  2.89  ...                   0   \n",
       "16                1                  2.77  ...                   0   \n",
       "17                1                  2.30  ...                   0   \n",
       "18                1                  2.77  ...                   0   \n",
       "19                0                  2.08  ...                   0   \n",
       "\n",
       "    comp5_inv_missing  comp8_rate_missing  comp8_inv_missing  \\\n",
       "0                   1                   1                  1   \n",
       "1                   1                   1                  1   \n",
       "2                   0                   1                  1   \n",
       "3                   0                   1                  1   \n",
       "4                   0                   1                  1   \n",
       "5                   1                   1                  1   \n",
       "6                   0                   1                  1   \n",
       "7                   0                   1                  1   \n",
       "8                   0                   1                  1   \n",
       "9                   0                   1                  1   \n",
       "10                  0                   1                  1   \n",
       "11                  1                   1                  1   \n",
       "12                  1                   1                  1   \n",
       "13                  0                   1                  1   \n",
       "14                  0                   1                  1   \n",
       "15                  0                   1                  1   \n",
       "16                  0                   1                  1   \n",
       "17                  0                   1                  1   \n",
       "18                  0                   1                  1   \n",
       "19                  0                   1                  1   \n",
       "\n",
       "    price_diff_vs_hist  price_rank  review_rank  star_rating_bucket  \\\n",
       "0               113.97        22.0         13.0                   1   \n",
       "1               113.07        21.0         13.0                   1   \n",
       "2                44.84         3.0          5.0                   0   \n",
       "3               137.97        25.0         13.0                   1   \n",
       "4                74.28        11.0         13.0                   1   \n",
       "5                79.47        15.0         13.0                   1   \n",
       "6                74.37        11.0         13.0                   1   \n",
       "7                48.19         5.0         13.0                   0   \n",
       "8                45.63         4.0          5.0                   0   \n",
       "9                78.55        14.0          8.0                   1   \n",
       "10              140.41        26.0          8.0                   1   \n",
       "11               40.38         1.0          1.0                   0   \n",
       "12               84.19        16.0         13.0                   1   \n",
       "13               99.10        18.0         13.0                   1   \n",
       "14               74.05        11.0          8.0                   1   \n",
       "15              144.21        27.0         13.0                   1   \n",
       "16               85.43        17.0          8.0                   1   \n",
       "17              153.81        28.0         13.0                   2   \n",
       "18               99.08        19.0         13.0                   1   \n",
       "19               54.26         7.0          2.0                   0   \n",
       "\n",
       "    prop_booking_rate  location_score_ratio  \n",
       "0            0.043011             42.540877  \n",
       "1            0.053279             31.313012  \n",
       "2            0.013423             48.732242  \n",
       "3            0.013793             42.773124  \n",
       "4            0.014634             14.066313  \n",
       "5            0.075000             12.595148  \n",
       "6            0.032086             23.767403  \n",
       "7            0.012579            204.923968  \n",
       "8            0.034247             27.224353  \n",
       "9            0.050891             12.612940  \n",
       "10           0.028986             22.890670  \n",
       "11           0.000000            223.365173  \n",
       "12           0.027701             11.917034  \n",
       "13           0.018293             12.250674  \n",
       "14           0.005780             62.003862  \n",
       "15           0.005128             12.719511  \n",
       "16           0.032558             13.828566  \n",
       "17           0.030568             25.695453  \n",
       "18           0.011364             13.252954  \n",
       "19           0.000000             26.731783  \n",
       "\n",
       "[20 rows x 53 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (2.0.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns in Train but NOT in Test:\n",
      "set()\n",
      "\n",
      "✅ Columns in Test but NOT in Train:\n",
      "set()\n",
      "\n",
      "✅ Do train and test have the same columns?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare columns in train and test (excluding target)\n",
    "train_cols = set(X_train.columns)\n",
    "test_cols = set(X_test.columns)\n",
    "\n",
    "# If srch_id was dropped from train before modeling, you can temporarily re-add it for this check\n",
    "if 'srch_id' not in X_train.columns and 'srch_id' in X_test.columns:\n",
    "    train_cols.add('srch_id')\n",
    "\n",
    "print(\"✅ Columns in Train but NOT in Test:\")\n",
    "print(train_cols - test_cols)\n",
    "\n",
    "print(\"\\n✅ Columns in Test but NOT in Train:\")\n",
    "print(test_cols - train_cols)\n",
    "\n",
    "print(\"\\n✅ Do train and test have the same columns?\")\n",
    "print(train_cols == test_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training Fold 1\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's ndcg@5: 0.619283\n",
      "[20]\tval's ndcg@5: 0.622156\n",
      "[30]\tval's ndcg@5: 0.623142\n",
      "[40]\tval's ndcg@5: 0.625257\n",
      "[50]\tval's ndcg@5: 0.625974\n",
      "[60]\tval's ndcg@5: 0.627165\n",
      "[70]\tval's ndcg@5: 0.628051\n",
      "[80]\tval's ndcg@5: 0.628903\n",
      "[90]\tval's ndcg@5: 0.629569\n",
      "[100]\tval's ndcg@5: 0.630078\n",
      "[110]\tval's ndcg@5: 0.630745\n",
      "[120]\tval's ndcg@5: 0.631718\n",
      "[130]\tval's ndcg@5: 0.632268\n",
      "[140]\tval's ndcg@5: 0.6327\n",
      "[150]\tval's ndcg@5: 0.63303\n",
      "[160]\tval's ndcg@5: 0.633649\n",
      "[170]\tval's ndcg@5: 0.633843\n",
      "[180]\tval's ndcg@5: 0.634101\n",
      "[190]\tval's ndcg@5: 0.634485\n",
      "[200]\tval's ndcg@5: 0.63443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[192]\tval's ndcg@5: 0.634545\n",
      "✅ Saved: models/lgbm_folds/lgbm_fold_1.pkl\n",
      "\n",
      "🔁 Training Fold 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's ndcg@5: 0.618151\n",
      "[20]\tval's ndcg@5: 0.621668\n",
      "[30]\tval's ndcg@5: 0.623228\n",
      "[40]\tval's ndcg@5: 0.624841\n",
      "[50]\tval's ndcg@5: 0.625727\n",
      "[60]\tval's ndcg@5: 0.627135\n",
      "[70]\tval's ndcg@5: 0.628368\n",
      "[80]\tval's ndcg@5: 0.629351\n",
      "[90]\tval's ndcg@5: 0.62988\n",
      "[100]\tval's ndcg@5: 0.630703\n",
      "[110]\tval's ndcg@5: 0.631123\n",
      "[120]\tval's ndcg@5: 0.632179\n",
      "[130]\tval's ndcg@5: 0.632961\n",
      "[140]\tval's ndcg@5: 0.633235\n",
      "[150]\tval's ndcg@5: 0.633737\n",
      "[160]\tval's ndcg@5: 0.634599\n",
      "[170]\tval's ndcg@5: 0.63491\n",
      "[180]\tval's ndcg@5: 0.635432\n",
      "[190]\tval's ndcg@5: 0.635692\n",
      "[200]\tval's ndcg@5: 0.635957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[196]\tval's ndcg@5: 0.636127\n",
      "✅ Saved: models/lgbm_folds/lgbm_fold_2.pkl\n",
      "\n",
      "🔁 Training Fold 3\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's ndcg@5: 0.61923\n",
      "[20]\tval's ndcg@5: 0.622468\n",
      "[30]\tval's ndcg@5: 0.623903\n",
      "[40]\tval's ndcg@5: 0.625284\n",
      "[50]\tval's ndcg@5: 0.626423\n",
      "[60]\tval's ndcg@5: 0.627688\n",
      "[70]\tval's ndcg@5: 0.628435\n",
      "[80]\tval's ndcg@5: 0.62983\n",
      "[90]\tval's ndcg@5: 0.631183\n",
      "[100]\tval's ndcg@5: 0.631941\n",
      "[110]\tval's ndcg@5: 0.632746\n",
      "[120]\tval's ndcg@5: 0.633462\n",
      "[130]\tval's ndcg@5: 0.633808\n",
      "[140]\tval's ndcg@5: 0.634029\n",
      "[150]\tval's ndcg@5: 0.634449\n",
      "[160]\tval's ndcg@5: 0.634972\n",
      "[170]\tval's ndcg@5: 0.635124\n",
      "[180]\tval's ndcg@5: 0.635477\n",
      "[190]\tval's ndcg@5: 0.635656\n",
      "[200]\tval's ndcg@5: 0.636237\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tval's ndcg@5: 0.636237\n",
      "✅ Saved: models/lgbm_folds/lgbm_fold_3.pkl\n",
      "\n",
      "🔁 Training Fold 4\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's ndcg@5: 0.619606\n",
      "[20]\tval's ndcg@5: 0.622936\n",
      "[30]\tval's ndcg@5: 0.624393\n",
      "[40]\tval's ndcg@5: 0.625663\n",
      "[50]\tval's ndcg@5: 0.626821\n",
      "[60]\tval's ndcg@5: 0.628505\n",
      "[70]\tval's ndcg@5: 0.629194\n",
      "[80]\tval's ndcg@5: 0.630129\n",
      "[90]\tval's ndcg@5: 0.631311\n",
      "[100]\tval's ndcg@5: 0.632\n",
      "[110]\tval's ndcg@5: 0.632852\n",
      "[120]\tval's ndcg@5: 0.633475\n",
      "[130]\tval's ndcg@5: 0.634192\n",
      "[140]\tval's ndcg@5: 0.635177\n",
      "[150]\tval's ndcg@5: 0.635375\n",
      "[160]\tval's ndcg@5: 0.635951\n",
      "[170]\tval's ndcg@5: 0.636028\n",
      "Early stopping, best iteration is:\n",
      "[168]\tval's ndcg@5: 0.636113\n",
      "✅ Saved: models/lgbm_folds/lgbm_fold_4.pkl\n",
      "\n",
      "🔁 Training Fold 5\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's ndcg@5: 0.620339\n",
      "[20]\tval's ndcg@5: 0.622705\n",
      "[30]\tval's ndcg@5: 0.624303\n",
      "[40]\tval's ndcg@5: 0.625382\n",
      "[50]\tval's ndcg@5: 0.627056\n",
      "[60]\tval's ndcg@5: 0.627904\n",
      "[70]\tval's ndcg@5: 0.629151\n",
      "[80]\tval's ndcg@5: 0.629904\n",
      "[90]\tval's ndcg@5: 0.631285\n",
      "[100]\tval's ndcg@5: 0.632237\n",
      "[110]\tval's ndcg@5: 0.633067\n",
      "[120]\tval's ndcg@5: 0.633936\n",
      "[130]\tval's ndcg@5: 0.634616\n",
      "[140]\tval's ndcg@5: 0.634873\n",
      "[150]\tval's ndcg@5: 0.635395\n",
      "[160]\tval's ndcg@5: 0.635811\n",
      "[170]\tval's ndcg@5: 0.636052\n",
      "[180]\tval's ndcg@5: 0.636549\n",
      "[190]\tval's ndcg@5: 0.636872\n",
      "[200]\tval's ndcg@5: 0.637137\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tval's ndcg@5: 0.637137\n",
      "✅ Saved: models/lgbm_folds/lgbm_fold_5.pkl\n",
      "\n",
      "✅ LightGBM LambdaRank training complete.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# === Setup ===\n",
    "os.makedirs(\"models/lgbm_folds\", exist_ok=True)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "kf = GroupKFold(n_splits=5)\n",
    "group_values = X_train['srch_id'].values\n",
    "drop_cols = ['srch_id', 'date_time']\n",
    "\n",
    "# === Store predictions ===\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# === Train & Save each fold ===\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train, groups=group_values), start=1):\n",
    "    print(f\"\\n🔁 Training Fold {fold}\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    group_tr = X_tr.groupby('srch_id').size().values\n",
    "    group_val = X_val.groupby('srch_id').size().values\n",
    "\n",
    "    train_data = lgb.Dataset(X_tr.drop(columns=drop_cols), label=y_tr, group=group_tr)\n",
    "    valid_data = lgb.Dataset(X_val.drop(columns=drop_cols), label=y_val, group=group_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=[\"val\"],\n",
    "        num_boost_round=200,\n",
    "        callbacks=[lgb.early_stopping(10), lgb.log_evaluation(10)]\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"models/lgbm_folds/lgbm_fold_{fold}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"✅ Saved: {model_path}\")\n",
    "\n",
    "    # Predict on validation fold\n",
    "    oof_preds[val_idx] = model.predict(X_val.drop(columns=drop_cols))\n",
    "\n",
    "    # Predict on test set\n",
    "    test_preds += model.predict(X_test.drop(columns=drop_cols))\n",
    "\n",
    "# === Finalize predictions ===\n",
    "test_preds /= 5  # average across 5 folds\n",
    "np.save(\"models/lgbm_oof_preds.npy\", oof_preds)\n",
    "np.save(\"models/lgbm_test_preds.npy\", test_preds)\n",
    "\n",
    "print(\"\\n✅ LightGBM LambdaRank training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Load predictions and srch_id/prop_id\n",
    "lgbm_oof = np.load(\"models/lgbm_oof_preds.npy\")\n",
    "lgbm_test = np.load(\"models/lgbm_test_preds.npy\")\n",
    "\n",
    "# 1D → 2D because Ridge expects 2D input\n",
    "X_meta = lgbm_oof.reshape(-1, 1)\n",
    "X_meta_test = lgbm_test.reshape(-1, 1)\n",
    "\n",
    "# Train meta-model\n",
    "ridge = RidgeCV()\n",
    "ridge.fit(X_meta, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "final_preds = ridge.predict(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file created: submission_lgbm_ridge.csv\n"
     ]
    }
   ],
   "source": [
    "submission_df = X_test[['srch_id', 'prop_id']].copy()\n",
    "submission_df['score'] = final_preds\n",
    "\n",
    "# Sort by srch_id and score descending\n",
    "submission_df = submission_df.sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "\n",
    "# Final format\n",
    "submission_df = submission_df[['srch_id', 'prop_id']]\n",
    "submission_df.to_csv(\"submission_lgbm_ridge.csv\", index=False)\n",
    "\n",
    "print(\"✅ Submission file created: submission_lgbm_ridge.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE ABOVE CODE WAS ABLE TO ACHEIVE A SCORE OF 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BELOW THE ENSEMBLE MODEL FAILED TO MATCH THE ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (2.0.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 XGBoost - Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:13:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-ndcg@5:0.59194\n",
      "[10]\tvalidation-ndcg@5:0.60881\n",
      "[20]\tvalidation-ndcg@5:0.61069\n",
      "[30]\tvalidation-ndcg@5:0.61234\n",
      "[40]\tvalidation-ndcg@5:0.61292\n",
      "[50]\tvalidation-ndcg@5:0.61408\n",
      "[60]\tvalidation-ndcg@5:0.61497\n",
      "[70]\tvalidation-ndcg@5:0.61568\n",
      "[80]\tvalidation-ndcg@5:0.61676\n",
      "[90]\tvalidation-ndcg@5:0.61810\n",
      "[100]\tvalidation-ndcg@5:0.61911\n",
      "[110]\tvalidation-ndcg@5:0.61973\n",
      "[120]\tvalidation-ndcg@5:0.62066\n",
      "[130]\tvalidation-ndcg@5:0.62123\n",
      "[140]\tvalidation-ndcg@5:0.62196\n",
      "[150]\tvalidation-ndcg@5:0.62249\n",
      "[160]\tvalidation-ndcg@5:0.62279\n",
      "[170]\tvalidation-ndcg@5:0.62420\n",
      "[180]\tvalidation-ndcg@5:0.62463\n",
      "[190]\tvalidation-ndcg@5:0.62546\n",
      "[199]\tvalidation-ndcg@5:0.62581\n",
      "\n",
      "🔁 XGBoost - Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:15:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-ndcg@5:0.59311\n",
      "[10]\tvalidation-ndcg@5:0.60936\n",
      "[20]\tvalidation-ndcg@5:0.61064\n",
      "[30]\tvalidation-ndcg@5:0.61151\n",
      "[40]\tvalidation-ndcg@5:0.61232\n",
      "[50]\tvalidation-ndcg@5:0.61317\n",
      "[60]\tvalidation-ndcg@5:0.61391\n",
      "[70]\tvalidation-ndcg@5:0.61533\n",
      "[80]\tvalidation-ndcg@5:0.61668\n",
      "[90]\tvalidation-ndcg@5:0.61779\n",
      "[100]\tvalidation-ndcg@5:0.61851\n",
      "[110]\tvalidation-ndcg@5:0.61977\n",
      "[120]\tvalidation-ndcg@5:0.62055\n",
      "[130]\tvalidation-ndcg@5:0.62123\n",
      "[140]\tvalidation-ndcg@5:0.62217\n",
      "[150]\tvalidation-ndcg@5:0.62292\n",
      "[160]\tvalidation-ndcg@5:0.62332\n",
      "[170]\tvalidation-ndcg@5:0.62396\n",
      "[180]\tvalidation-ndcg@5:0.62474\n",
      "[190]\tvalidation-ndcg@5:0.62524\n",
      "[199]\tvalidation-ndcg@5:0.62590\n",
      "\n",
      "🔁 XGBoost - Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:17:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-ndcg@5:0.59238\n",
      "[10]\tvalidation-ndcg@5:0.60734\n",
      "[20]\tvalidation-ndcg@5:0.60932\n",
      "[30]\tvalidation-ndcg@5:0.61082\n",
      "[40]\tvalidation-ndcg@5:0.61151\n",
      "[50]\tvalidation-ndcg@5:0.61276\n",
      "[60]\tvalidation-ndcg@5:0.61367\n",
      "[70]\tvalidation-ndcg@5:0.61496\n",
      "[80]\tvalidation-ndcg@5:0.61613\n",
      "[90]\tvalidation-ndcg@5:0.61731\n",
      "[100]\tvalidation-ndcg@5:0.61865\n",
      "[110]\tvalidation-ndcg@5:0.61953\n",
      "[120]\tvalidation-ndcg@5:0.62043\n",
      "[130]\tvalidation-ndcg@5:0.62150\n",
      "[140]\tvalidation-ndcg@5:0.62238\n",
      "[150]\tvalidation-ndcg@5:0.62308\n",
      "[160]\tvalidation-ndcg@5:0.62409\n",
      "[170]\tvalidation-ndcg@5:0.62472\n",
      "[180]\tvalidation-ndcg@5:0.62540\n",
      "[190]\tvalidation-ndcg@5:0.62598\n",
      "[199]\tvalidation-ndcg@5:0.62658\n",
      "\n",
      "🔁 XGBoost - Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:20:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-ndcg@5:0.59328\n",
      "[10]\tvalidation-ndcg@5:0.60831\n",
      "[20]\tvalidation-ndcg@5:0.60913\n",
      "[30]\tvalidation-ndcg@5:0.60957\n",
      "[40]\tvalidation-ndcg@5:0.61096\n",
      "[50]\tvalidation-ndcg@5:0.61175\n",
      "[60]\tvalidation-ndcg@5:0.61246\n",
      "[70]\tvalidation-ndcg@5:0.61390\n",
      "[80]\tvalidation-ndcg@5:0.61545\n",
      "[90]\tvalidation-ndcg@5:0.61676\n",
      "[100]\tvalidation-ndcg@5:0.61764\n",
      "[110]\tvalidation-ndcg@5:0.61846\n",
      "[120]\tvalidation-ndcg@5:0.61944\n",
      "[130]\tvalidation-ndcg@5:0.62081\n",
      "[140]\tvalidation-ndcg@5:0.62159\n",
      "[150]\tvalidation-ndcg@5:0.62259\n",
      "[160]\tvalidation-ndcg@5:0.62336\n",
      "[170]\tvalidation-ndcg@5:0.62403\n",
      "[180]\tvalidation-ndcg@5:0.62462\n",
      "[190]\tvalidation-ndcg@5:0.62549\n",
      "[199]\tvalidation-ndcg@5:0.62620\n",
      "\n",
      "🔁 XGBoost - Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/callback.py:386: UserWarning: [09:22:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-ndcg@5:0.59257\n",
      "[10]\tvalidation-ndcg@5:0.60771\n",
      "[20]\tvalidation-ndcg@5:0.61016\n",
      "[30]\tvalidation-ndcg@5:0.61068\n",
      "[40]\tvalidation-ndcg@5:0.61216\n",
      "[50]\tvalidation-ndcg@5:0.61301\n",
      "[60]\tvalidation-ndcg@5:0.61397\n",
      "[70]\tvalidation-ndcg@5:0.61529\n",
      "[80]\tvalidation-ndcg@5:0.61645\n",
      "[90]\tvalidation-ndcg@5:0.61732\n",
      "[100]\tvalidation-ndcg@5:0.61838\n",
      "[110]\tvalidation-ndcg@5:0.61933\n",
      "[120]\tvalidation-ndcg@5:0.62034\n",
      "[130]\tvalidation-ndcg@5:0.62118\n",
      "[140]\tvalidation-ndcg@5:0.62214\n",
      "[150]\tvalidation-ndcg@5:0.62270\n",
      "[160]\tvalidation-ndcg@5:0.62346\n",
      "[170]\tvalidation-ndcg@5:0.62425\n",
      "[180]\tvalidation-ndcg@5:0.62481\n",
      "[190]\tvalidation-ndcg@5:0.62529\n",
      "[199]\tvalidation-ndcg@5:0.62577\n",
      "✅ XGBoost training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Setup\n",
    "os.makedirs(\"models/xgb_folds\", exist_ok=True)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"rank:pairwise\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 6,\n",
    "    \"verbosity\": 1,\n",
    "    \"eval_metric\": \"ndcg@5\"\n",
    "}\n",
    "\n",
    "kf = GroupKFold(n_splits=5)\n",
    "group_values = X_train['srch_id'].values\n",
    "drop_cols = ['srch_id', 'date_time']\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Train across 5 folds\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train, groups=group_values), start=1):\n",
    "    print(f\"\\n🔁 XGBoost - Fold {fold}\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    group_tr = X_tr.groupby('srch_id').size().values\n",
    "    group_val = X_val.groupby('srch_id').size().values\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr.drop(columns=drop_cols), label=y_tr)\n",
    "    dvalid = xgb.DMatrix(X_val.drop(columns=drop_cols), label=y_val)\n",
    "    dtest = xgb.DMatrix(X_test.drop(columns=drop_cols))\n",
    "\n",
    "    dtrain.set_group(group_tr)\n",
    "    dvalid.set_group(group_val)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=200,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "\n",
    "    joblib.dump(model, f\"models/xgb_folds/xgb_fold_{fold}.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    oof_preds[val_idx] = model.predict(xgb.DMatrix(X_val.drop(columns=drop_cols)))\n",
    "    test_preds += model.predict(dtest)\n",
    "\n",
    "# Average test predictions across folds\n",
    "test_preds /= 5\n",
    "\n",
    "# Save\n",
    "np.save(\"models/xgb_oof_preds.npy\", oof_preds)\n",
    "np.save(\"models/xgb_test_preds.npy\", test_preds)\n",
    "\n",
    "print(\"✅ XGBoost training complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (2.0.0)\n",
      "Requirement already satisfied: pandas>=0.24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from catboost) (6.1.0)\n",
      "Requirement already satisfied: six in /Users/rahilsharma/Library/Python/3.12/lib/python/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rahilsharma/Library/Python/3.12/lib/python/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rahilsharma/Library/Python/3.12/lib/python/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly->catboost) (1.39.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 CatBoost - Fold 1\n",
      "0:\ttest: 0.5272629\tbest: 0.5272629 (0)\ttotal: 2.53s\tremaining: 8m 22s\n",
      "10:\ttest: 0.5978337\tbest: 0.5978337 (10)\ttotal: 22.3s\tremaining: 6m 22s\n",
      "20:\ttest: 0.6047068\tbest: 0.6047068 (20)\ttotal: 40.8s\tremaining: 5m 47s\n",
      "30:\ttest: 0.6086980\tbest: 0.6086980 (30)\ttotal: 57.2s\tremaining: 5m 11s\n",
      "40:\ttest: 0.6116466\tbest: 0.6116466 (40)\ttotal: 1m 13s\tremaining: 4m 43s\n",
      "50:\ttest: 0.6147988\tbest: 0.6147988 (50)\ttotal: 1m 28s\tremaining: 4m 18s\n",
      "60:\ttest: 0.6176856\tbest: 0.6176856 (60)\ttotal: 1m 46s\tremaining: 4m 1s\n",
      "70:\ttest: 0.6196941\tbest: 0.6196941 (70)\ttotal: 2m 5s\tremaining: 3m 47s\n",
      "80:\ttest: 0.6212656\tbest: 0.6212656 (80)\ttotal: 2m 23s\tremaining: 3m 30s\n",
      "90:\ttest: 0.6230012\tbest: 0.6230012 (90)\ttotal: 2m 44s\tremaining: 3m 17s\n",
      "100:\ttest: 0.6239594\tbest: 0.6240103 (98)\ttotal: 3m 4s\tremaining: 3m 1s\n",
      "110:\ttest: 0.6255987\tbest: 0.6255987 (110)\ttotal: 3m 21s\tremaining: 2m 41s\n",
      "120:\ttest: 0.6263427\tbest: 0.6263427 (120)\ttotal: 3m 38s\tremaining: 2m 22s\n",
      "130:\ttest: 0.6270471\tbest: 0.6270471 (130)\ttotal: 3m 56s\tremaining: 2m 4s\n",
      "140:\ttest: 0.6274547\tbest: 0.6274547 (140)\ttotal: 4m 14s\tremaining: 1m 46s\n",
      "150:\ttest: 0.6283735\tbest: 0.6283735 (150)\ttotal: 4m 35s\tremaining: 1m 29s\n",
      "160:\ttest: 0.6289402\tbest: 0.6289402 (160)\ttotal: 4m 53s\tremaining: 1m 11s\n",
      "170:\ttest: 0.6293892\tbest: 0.6294258 (169)\ttotal: 5m 16s\tremaining: 53.6s\n",
      "180:\ttest: 0.6298342\tbest: 0.6298401 (179)\ttotal: 5m 35s\tremaining: 35.3s\n",
      "190:\ttest: 0.6303944\tbest: 0.6303944 (190)\ttotal: 5m 55s\tremaining: 16.7s\n",
      "199:\ttest: 0.6310218\tbest: 0.6310218 (199)\ttotal: 6m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6310218267\n",
      "bestIteration = 199\n",
      "\n",
      "\n",
      "🔁 CatBoost - Fold 2\n",
      "0:\ttest: 0.5253794\tbest: 0.5253794 (0)\ttotal: 2.48s\tremaining: 8m 14s\n",
      "10:\ttest: 0.5965985\tbest: 0.5965985 (10)\ttotal: 24.7s\tremaining: 7m 4s\n",
      "20:\ttest: 0.6035927\tbest: 0.6035927 (20)\ttotal: 44s\tremaining: 6m 15s\n",
      "30:\ttest: 0.6077899\tbest: 0.6077899 (30)\ttotal: 1m 3s\tremaining: 5m 44s\n",
      "40:\ttest: 0.6110124\tbest: 0.6110124 (40)\ttotal: 1m 21s\tremaining: 5m 14s\n",
      "50:\ttest: 0.6137189\tbest: 0.6137189 (50)\ttotal: 1m 37s\tremaining: 4m 45s\n",
      "60:\ttest: 0.6166448\tbest: 0.6166448 (60)\ttotal: 1m 54s\tremaining: 4m 20s\n",
      "70:\ttest: 0.6190740\tbest: 0.6190740 (70)\ttotal: 2m 9s\tremaining: 3m 55s\n",
      "80:\ttest: 0.6212866\tbest: 0.6212866 (80)\ttotal: 2m 25s\tremaining: 3m 33s\n",
      "90:\ttest: 0.6227984\tbest: 0.6227984 (90)\ttotal: 2m 40s\tremaining: 3m 12s\n",
      "100:\ttest: 0.6239186\tbest: 0.6239186 (100)\ttotal: 2m 56s\tremaining: 2m 52s\n",
      "110:\ttest: 0.6252223\tbest: 0.6252227 (109)\ttotal: 3m 11s\tremaining: 2m 33s\n",
      "120:\ttest: 0.6262735\tbest: 0.6262735 (120)\ttotal: 3m 26s\tremaining: 2m 15s\n",
      "130:\ttest: 0.6273952\tbest: 0.6273952 (130)\ttotal: 3m 42s\tremaining: 1m 56s\n",
      "140:\ttest: 0.6283066\tbest: 0.6283066 (140)\ttotal: 3m 57s\tremaining: 1m 39s\n",
      "150:\ttest: 0.6289676\tbest: 0.6289708 (149)\ttotal: 4m 13s\tremaining: 1m 22s\n",
      "160:\ttest: 0.6296433\tbest: 0.6296433 (160)\ttotal: 4m 28s\tremaining: 1m 5s\n",
      "170:\ttest: 0.6300923\tbest: 0.6301099 (168)\ttotal: 4m 45s\tremaining: 48.4s\n",
      "180:\ttest: 0.6305446\tbest: 0.6305446 (180)\ttotal: 5m 1s\tremaining: 31.6s\n",
      "190:\ttest: 0.6310439\tbest: 0.6310439 (190)\ttotal: 5m 16s\tremaining: 14.9s\n",
      "199:\ttest: 0.6313328\tbest: 0.6314074 (198)\ttotal: 5m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6314074438\n",
      "bestIteration = 198\n",
      "\n",
      "Shrink model to first 199 iterations.\n",
      "\n",
      "🔁 CatBoost - Fold 3\n",
      "0:\ttest: 0.5230723\tbest: 0.5230723 (0)\ttotal: 3.2s\tremaining: 10m 36s\n",
      "10:\ttest: 0.5971689\tbest: 0.5971689 (10)\ttotal: 21.3s\tremaining: 6m 5s\n",
      "20:\ttest: 0.6046203\tbest: 0.6046203 (20)\ttotal: 39.4s\tremaining: 5m 35s\n",
      "30:\ttest: 0.6088972\tbest: 0.6088972 (30)\ttotal: 54.8s\tremaining: 4m 58s\n",
      "40:\ttest: 0.6114783\tbest: 0.6114783 (40)\ttotal: 1m 11s\tremaining: 4m 35s\n",
      "50:\ttest: 0.6148980\tbest: 0.6148980 (50)\ttotal: 1m 27s\tremaining: 4m 14s\n",
      "60:\ttest: 0.6178128\tbest: 0.6178128 (60)\ttotal: 1m 42s\tremaining: 3m 53s\n",
      "70:\ttest: 0.6199390\tbest: 0.6199390 (70)\ttotal: 1m 57s\tremaining: 3m 34s\n",
      "80:\ttest: 0.6222850\tbest: 0.6222850 (80)\ttotal: 2m 12s\tremaining: 3m 14s\n",
      "90:\ttest: 0.6240058\tbest: 0.6240058 (90)\ttotal: 2m 27s\tremaining: 2m 56s\n",
      "100:\ttest: 0.6254340\tbest: 0.6254340 (100)\ttotal: 2m 42s\tremaining: 2m 38s\n",
      "110:\ttest: 0.6265565\tbest: 0.6265565 (110)\ttotal: 2m 56s\tremaining: 2m 21s\n",
      "120:\ttest: 0.6273479\tbest: 0.6273479 (120)\ttotal: 3m 10s\tremaining: 2m 4s\n",
      "130:\ttest: 0.6282513\tbest: 0.6282513 (130)\ttotal: 3m 25s\tremaining: 1m 48s\n",
      "140:\ttest: 0.6290430\tbest: 0.6290430 (140)\ttotal: 3m 39s\tremaining: 1m 31s\n",
      "150:\ttest: 0.6294345\tbest: 0.6295334 (149)\ttotal: 3m 53s\tremaining: 1m 15s\n",
      "160:\ttest: 0.6297613\tbest: 0.6298555 (158)\ttotal: 4m 8s\tremaining: 1m\n",
      "170:\ttest: 0.6303725\tbest: 0.6304947 (167)\ttotal: 4m 22s\tremaining: 44.5s\n",
      "180:\ttest: 0.6310081\tbest: 0.6310081 (180)\ttotal: 4m 37s\tremaining: 29.1s\n",
      "190:\ttest: 0.6313345\tbest: 0.6313345 (190)\ttotal: 4m 51s\tremaining: 13.7s\n",
      "199:\ttest: 0.6316953\tbest: 0.6317952 (198)\ttotal: 5m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6317951728\n",
      "bestIteration = 198\n",
      "\n",
      "Shrink model to first 199 iterations.\n",
      "\n",
      "🔁 CatBoost - Fold 4\n",
      "0:\ttest: 0.5195323\tbest: 0.5195323 (0)\ttotal: 1.68s\tremaining: 5m 33s\n",
      "10:\ttest: 0.5952862\tbest: 0.5952862 (10)\ttotal: 17.1s\tremaining: 4m 54s\n",
      "20:\ttest: 0.6035843\tbest: 0.6035843 (20)\ttotal: 31.6s\tremaining: 4m 29s\n",
      "30:\ttest: 0.6081170\tbest: 0.6081335 (29)\ttotal: 46.2s\tremaining: 4m 11s\n",
      "40:\ttest: 0.6114330\tbest: 0.6114330 (40)\ttotal: 1m\tremaining: 3m 55s\n",
      "50:\ttest: 0.6142337\tbest: 0.6142337 (50)\ttotal: 1m 16s\tremaining: 3m 43s\n",
      "60:\ttest: 0.6171281\tbest: 0.6171281 (60)\ttotal: 1m 33s\tremaining: 3m 32s\n",
      "70:\ttest: 0.6195166\tbest: 0.6195166 (70)\ttotal: 1m 47s\tremaining: 3m 16s\n",
      "80:\ttest: 0.6217346\tbest: 0.6217346 (80)\ttotal: 2m 2s\tremaining: 3m\n",
      "90:\ttest: 0.6235411\tbest: 0.6235411 (90)\ttotal: 2m 18s\tremaining: 2m 45s\n",
      "100:\ttest: 0.6249500\tbest: 0.6249574 (99)\ttotal: 2m 33s\tremaining: 2m 29s\n",
      "110:\ttest: 0.6262446\tbest: 0.6262446 (110)\ttotal: 2m 47s\tremaining: 2m 14s\n",
      "120:\ttest: 0.6273327\tbest: 0.6274382 (118)\ttotal: 3m 2s\tremaining: 1m 58s\n",
      "130:\ttest: 0.6282574\tbest: 0.6282574 (130)\ttotal: 3m 16s\tremaining: 1m 43s\n",
      "140:\ttest: 0.6289775\tbest: 0.6289775 (140)\ttotal: 3m 30s\tremaining: 1m 28s\n",
      "150:\ttest: 0.6298559\tbest: 0.6298559 (150)\ttotal: 3m 48s\tremaining: 1m 14s\n",
      "160:\ttest: 0.6301457\tbest: 0.6301875 (159)\ttotal: 4m 3s\tremaining: 58.9s\n",
      "170:\ttest: 0.6308638\tbest: 0.6308638 (170)\ttotal: 4m 18s\tremaining: 43.9s\n",
      "180:\ttest: 0.6316803\tbest: 0.6316803 (180)\ttotal: 4m 34s\tremaining: 28.8s\n",
      "190:\ttest: 0.6320452\tbest: 0.6320790 (184)\ttotal: 4m 52s\tremaining: 13.8s\n",
      "199:\ttest: 0.6323086\tbest: 0.6323120 (197)\ttotal: 5m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6323119732\n",
      "bestIteration = 197\n",
      "\n",
      "Shrink model to first 198 iterations.\n",
      "\n",
      "🔁 CatBoost - Fold 5\n",
      "0:\ttest: 0.5232850\tbest: 0.5232850 (0)\ttotal: 1.93s\tremaining: 6m 24s\n",
      "10:\ttest: 0.5987565\tbest: 0.5987565 (10)\ttotal: 22.4s\tremaining: 6m 25s\n",
      "20:\ttest: 0.6052295\tbest: 0.6053593 (19)\ttotal: 41.6s\tremaining: 5m 54s\n",
      "30:\ttest: 0.6093098\tbest: 0.6093098 (30)\ttotal: 1m 2s\tremaining: 5m 40s\n",
      "40:\ttest: 0.6122442\tbest: 0.6122442 (40)\ttotal: 1m 20s\tremaining: 5m 10s\n",
      "50:\ttest: 0.6150183\tbest: 0.6150183 (50)\ttotal: 1m 35s\tremaining: 4m 38s\n",
      "60:\ttest: 0.6176630\tbest: 0.6176630 (60)\ttotal: 1m 53s\tremaining: 4m 19s\n",
      "70:\ttest: 0.6201638\tbest: 0.6201638 (70)\ttotal: 2m 9s\tremaining: 3m 55s\n",
      "80:\ttest: 0.6219925\tbest: 0.6219925 (80)\ttotal: 2m 24s\tremaining: 3m 32s\n",
      "90:\ttest: 0.6235876\tbest: 0.6235876 (90)\ttotal: 2m 39s\tremaining: 3m 11s\n",
      "100:\ttest: 0.6249189\tbest: 0.6249189 (100)\ttotal: 2m 54s\tremaining: 2m 51s\n",
      "110:\ttest: 0.6261533\tbest: 0.6261533 (110)\ttotal: 3m 10s\tremaining: 2m 32s\n",
      "120:\ttest: 0.6273993\tbest: 0.6273993 (120)\ttotal: 3m 25s\tremaining: 2m 13s\n",
      "130:\ttest: 0.6282688\tbest: 0.6282688 (130)\ttotal: 3m 40s\tremaining: 1m 56s\n",
      "140:\ttest: 0.6291789\tbest: 0.6291789 (140)\ttotal: 3m 57s\tremaining: 1m 39s\n",
      "150:\ttest: 0.6298332\tbest: 0.6298332 (150)\ttotal: 4m 13s\tremaining: 1m 22s\n",
      "160:\ttest: 0.6306533\tbest: 0.6306533 (160)\ttotal: 4m 29s\tremaining: 1m 5s\n",
      "170:\ttest: 0.6311919\tbest: 0.6311919 (170)\ttotal: 4m 44s\tremaining: 48.3s\n",
      "180:\ttest: 0.6314406\tbest: 0.6314752 (178)\ttotal: 4m 59s\tremaining: 31.5s\n",
      "190:\ttest: 0.6322653\tbest: 0.6322653 (190)\ttotal: 5m 15s\tremaining: 14.9s\n",
      "199:\ttest: 0.6322744\tbest: 0.6324135 (194)\ttotal: 5m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.632413549\n",
      "bestIteration = 194\n",
      "\n",
      "Shrink model to first 195 iterations.\n",
      "✅ CatBoost training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRanker, Pool\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Setup\n",
    "os.makedirs(\"models/cat_folds\", exist_ok=True)\n",
    "\n",
    "kf = GroupKFold(n_splits=5)\n",
    "group_values = X_train['srch_id'].values\n",
    "drop_cols = ['srch_id', 'date_time']\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train, groups=group_values), start=1):\n",
    "    print(f\"\\n🔁 CatBoost - Fold {fold}\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    group_tr = X_tr.groupby('srch_id').size().values\n",
    "    group_val = X_val.groupby('srch_id').size().values\n",
    "\n",
    "    train_pool = Pool(\n",
    "        X_tr.drop(columns=drop_cols),\n",
    "        label=y_tr,\n",
    "        group_id=X_tr['srch_id']\n",
    "    )\n",
    "    val_pool = Pool(\n",
    "        X_val.drop(columns=drop_cols),\n",
    "        label=y_val,\n",
    "        group_id=X_val['srch_id']\n",
    "    )\n",
    "    test_pool = Pool(X_test.drop(columns=drop_cols), group_id=X_test['srch_id'])\n",
    "\n",
    "    model = CatBoostRanker(\n",
    "        iterations=200,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='YetiRank',\n",
    "        eval_metric='NDCG:top=5',\n",
    "        random_seed=42,\n",
    "        verbose=10\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=10)\n",
    "\n",
    "    joblib.dump(model, f\"models/cat_folds/cat_fold_{fold}.pkl\")\n",
    "\n",
    "    oof_preds[val_idx] = model.predict(val_pool)\n",
    "    test_preds += model.predict(test_pool)\n",
    "\n",
    "# Average test predictions\n",
    "test_preds /= 5\n",
    "\n",
    "np.save(\"models/cat_oof_preds.npy\", oof_preds)\n",
    "np.save(\"models/cat_test_preds.npy\", test_preds)\n",
    "\n",
    "print(\"✅ CatBoost training complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load base model predictions\n",
    "lgb_oof = np.load(\"models/lgbm_oof_preds.npy\").reshape(-1, 1)\n",
    "xgb_oof = np.load(\"models/xgb_oof_preds.npy\").reshape(-1, 1)\n",
    "cat_oof = np.load(\"models/cat_oof_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "lgb_test = np.load(\"models/lgbm_test_preds.npy\").reshape(-1, 1)\n",
    "xgb_test = np.load(\"models/xgb_test_preds.npy\").reshape(-1, 1)\n",
    "cat_test = np.load(\"models/cat_test_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "# Stack into feature matrix\n",
    "X_meta = np.hstack([lgb_oof, xgb_oof, cat_oof])\n",
    "X_meta_test = np.hstack([lgb_test, xgb_test, cat_test])\n",
    "\n",
    "# Meta-model\n",
    "meta_model = RidgeCV()\n",
    "meta_model.fit(X_meta, y_train)\n",
    "\n",
    "# Final prediction\n",
    "final_preds = meta_model.predict(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final stacked submission file saved: submission_stacked_ridge.csv\n"
     ]
    }
   ],
   "source": [
    "submission_df = X_test[['srch_id', 'prop_id']].copy()\n",
    "submission_df['score'] = final_preds\n",
    "\n",
    "# Sort by search and predicted score\n",
    "submission_df = submission_df.sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "\n",
    "# Final format\n",
    "submission_df = submission_df[['srch_id', 'prop_id']]\n",
    "submission_df.to_csv(\"submission_stacked_ridge.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final stacked submission file saved: submission_stacked_ridge.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load model predictions\n",
    "lgb_oof = np.load(\"models/lgbm_oof_preds.npy\").reshape(-1, 1)\n",
    "xgb_oof = np.load(\"models/xgb_oof_preds.npy\").reshape(-1, 1)\n",
    "cat_oof = np.load(\"models/cat_oof_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "lgb_test = np.load(\"models/lgbm_test_preds.npy\").reshape(-1, 1)\n",
    "xgb_test = np.load(\"models/xgb_test_preds.npy\").reshape(-1, 1)\n",
    "cat_test = np.load(\"models/cat_test_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "# Stack features\n",
    "X_meta = np.hstack([lgb_oof, xgb_oof, cat_oof])\n",
    "X_meta_test = np.hstack([lgb_test, xgb_test, cat_test])\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_meta, y_train)\n",
    "final_preds = rf.predict(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌲 RandomForest submission saved: submission_stacked_rf.csv\n"
     ]
    }
   ],
   "source": [
    "submission_df = X_test[['srch_id', 'prop_id']].copy()\n",
    "submission_df['score'] = final_preds\n",
    "\n",
    "# Sort and prepare\n",
    "submission_df = submission_df.sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "submission_df = submission_df[['srch_id', 'prop_id']]\n",
    "submission_df.to_csv(\"submission_stacked_rf.csv\", index=False)\n",
    "\n",
    "print(\"🌲 RandomForest submission saved: submission_stacked_rf.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load base model OOF and test predictions\n",
    "lgb_oof = np.load(\"models/lgbm_oof_preds.npy\").reshape(-1, 1)\n",
    "xgb_oof = np.load(\"models/xgb_oof_preds.npy\").reshape(-1, 1)\n",
    "cat_oof = np.load(\"models/cat_oof_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "lgb_test = np.load(\"models/lgbm_test_preds.npy\").reshape(-1, 1)\n",
    "xgb_test = np.load(\"models/xgb_test_preds.npy\").reshape(-1, 1)\n",
    "cat_test = np.load(\"models/cat_test_preds.npy\").reshape(-1, 1)\n",
    "\n",
    "# === Enriched meta features: OOF ===\n",
    "X_meta = np.hstack([\n",
    "    lgb_oof,\n",
    "    xgb_oof,\n",
    "    cat_oof,\n",
    "    (lgb_oof + xgb_oof + cat_oof) / 3,              # mean\n",
    "    (lgb_oof - xgb_oof),                            # disagreement\n",
    "    (lgb_oof - cat_oof),\n",
    "    (xgb_oof - cat_oof),\n",
    "    (lgb_oof * cat_oof),                            # interactions\n",
    "    (xgb_oof * cat_oof),\n",
    "    (lgb_oof * xgb_oof),\n",
    "])\n",
    "\n",
    "# === Enriched meta features: TEST ===\n",
    "X_meta_test = np.hstack([\n",
    "    lgb_test,\n",
    "    xgb_test,\n",
    "    cat_test,\n",
    "    (lgb_test + xgb_test + cat_test) / 3,\n",
    "    (lgb_test - xgb_test),\n",
    "    (lgb_test - cat_test),\n",
    "    (xgb_test - cat_test),\n",
    "    (lgb_test * cat_test),\n",
    "    (xgb_test * cat_test),\n",
    "    (lgb_test * xgb_test),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tval's rmse: 0.162756\n",
      "[20]\tval's rmse: 0.161429\n",
      "[30]\tval's rmse: 0.160693\n",
      "[40]\tval's rmse: 0.160283\n",
      "[50]\tval's rmse: 0.160054\n",
      "[60]\tval's rmse: 0.159925\n",
      "[70]\tval's rmse: 0.159851\n",
      "[80]\tval's rmse: 0.159808\n",
      "[90]\tval's rmse: 0.159785\n",
      "[100]\tval's rmse: 0.15977\n",
      "[110]\tval's rmse: 0.159761\n",
      "[120]\tval's rmse: 0.159756\n",
      "[130]\tval's rmse: 0.159751\n",
      "[140]\tval's rmse: 0.159748\n",
      "[150]\tval's rmse: 0.159746\n",
      "[160]\tval's rmse: 0.159745\n",
      "[170]\tval's rmse: 0.159744\n",
      "[180]\tval's rmse: 0.159744\n",
      "Early stopping, best iteration is:\n",
      "[174]\tval's rmse: 0.159743\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split for validation (not CV — just meta layer)\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    X_meta, y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM dataset\n",
    "train_data = lgb.Dataset(X_meta_train, label=y_meta_train)\n",
    "val_data = lgb.Dataset(X_meta_val, label=y_meta_val)\n",
    "\n",
    "# LightGBM params for meta-model\n",
    "meta_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"ndcg_eval_at\": [5],\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 15,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = lgb.train(\n",
    "    meta_params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    valid_names=[\"val\"],\n",
    "    num_boost_round=200,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=10),\n",
    "        lgb.log_evaluation(period=10)  # replaces verbose_eval=10\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Predict test scores\n",
    "final_preds = meta_model.predict(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission_superstack_lgbm.csv is ready.\n"
     ]
    }
   ],
   "source": [
    "submission_df = X_test[['srch_id', 'prop_id']].copy()\n",
    "submission_df['score'] = final_preds\n",
    "\n",
    "# Groupwise rank normalization\n",
    "submission_df['score'] = submission_df.groupby('srch_id')['score'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-5)\n",
    ")\n",
    "\n",
    "# Final sort and format\n",
    "submission_df = submission_df.sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "submission_df = submission_df[['srch_id', 'prop_id']]\n",
    "submission_df.to_csv(\"submission_superstack_lgbm.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_superstack_lgbm.csv is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
